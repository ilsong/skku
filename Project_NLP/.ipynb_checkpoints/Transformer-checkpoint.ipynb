{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11739370876483508060\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7917938279\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17049503785459007246\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:82:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess= tf.Session(config=config)\n",
    "\n",
    "import sys\n",
    "from tensorflow.python.client import device_lib\n",
    "print (device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from keras.initializers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from tqdm import tqdm\n",
    "    from dataloader import TokenList, pad_to_longest\n",
    "    # for transformer\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(Layer):\n",
    "    def __init__(self, eps=1e-6, **kwargs):\n",
    "        self.eps = eps\n",
    "        super(LayerNormalization, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:], initializer=Ones(), trainable=True)\n",
    "        self.beta = self.add_weight(name='beta', shape=input_shape[-1:], initializer=Zeros(), trainable=True)\n",
    "        super(LayerNormalization, self).build(input_shape)\n",
    "    def call(self, x):\n",
    "        mean = K.mean(x, axis=-1, keepdims=True)\n",
    "        std = K.std(x, axis=-1, keepdims=True)\n",
    "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention():\n",
    "    def __init__(self, attn_dropout=0.1):\n",
    "        self.dropout = Dropout(attn_dropout)\n",
    "    def __call__(self, q, k, v, mask):\n",
    "        temper = tf.sqrt(tf.cast(tf.shape(k)[-1], dtype='float32'))\n",
    "        attn = Lambda(lambda x:K.batch_dot(x[0],x[1], axes=[2,2])/temper)([q,k])\n",
    "        if mask is not None:\n",
    "            mmask = Lambda(lambda x:(-1e+9)*(1.-K.cast(x, 'float32')))(mask)\n",
    "            attn = Add()([attn, mmask])\n",
    "        attn = Activation('softmax')(attn)\n",
    "        attn = self.dropout(attn)\n",
    "        output = Lambda(lambda x:K.batch_dot(x[0], x[1]))([attn, v])\n",
    "        return output, attn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention():\n",
    "    # mode 0 - big martixes, faster; mode 1 - more clear implementation\n",
    "    def __init__(self, n_head, d_model, dropout, mode=0):\n",
    "        self.mode = mode\n",
    "        self.n_head = n_head\n",
    "        self.d_k = self.d_v = d_k = d_v = d_model // n_head\n",
    "        self.dropout = dropout\n",
    "        if mode == 0:\n",
    "            self.qs_layer = Dense(n_head*d_k, use_bias=False)\n",
    "            self.ks_layer = Dense(n_head*d_k, use_bias=False)\n",
    "            self.vs_layer = Dense(n_head*d_v, use_bias=False)\n",
    "        elif mode == 1:\n",
    "            self.qs_layers = []\n",
    "            self.ks_layers = []\n",
    "            self.vs_layers = []\n",
    "            for _ in range(n_head):\n",
    "                self.qs_layers.append(TimeDistributed(Dense(d_k, use_bias=False)))\n",
    "                self.ks_layers.append(TimeDistributed(Dense(d_k, use_bias=False)))\n",
    "                self.vs_layers.append(TimeDistributed(Dense(d_v, use_bias=False)))\n",
    "        self.attention = ScaledDotProductAttention()\n",
    "        self.w_o = TimeDistributed(Dense(d_model))  \n",
    "    def __call__(self, q, k, v, mask=None):\n",
    "        d_k, d_v = self.d_k, self.d_v\n",
    "        n_head = self.n_head    \n",
    "        if self.mode == 0:\n",
    "            qs = self.qs_layer(q)  # [batch_size, len_q, n_head*d_k]\n",
    "            ks = self.ks_layer(k)\n",
    "            vs = self.vs_layer(v)   \n",
    "            def reshape1(x):\n",
    "                s = tf.shape(x)   # [batch_size, len_q, n_head * d_k]\n",
    "                x = tf.reshape(x, [s[0], s[1], n_head, s[2]//n_head])\n",
    "                x = tf.transpose(x, [2, 0, 1, 3])  \n",
    "                x = tf.reshape(x, [-1, s[1], s[2]//n_head])  # [n_head * batch_size, len_q, d_k]\n",
    "                return x\n",
    "            qs = Lambda(reshape1)(qs)\n",
    "            ks = Lambda(reshape1)(ks)\n",
    "            vs = Lambda(reshape1)(vs)   \n",
    "            if mask is not None:\n",
    "                mask = Lambda(lambda x:K.repeat_elements(x, n_head, 0))(mask)\n",
    "            head, attn = self.attention(qs, ks, vs, mask=mask)  \n",
    "\n",
    "            def reshape2(x):\n",
    "                s = tf.shape(x)   # [n_head * batch_size, len_v, d_v]\n",
    "                x = tf.reshape(x, [n_head, -1, s[1], s[2]]) \n",
    "                x = tf.transpose(x, [1, 2, 0, 3])\n",
    "                x = tf.reshape(x, [-1, s[1], n_head*d_v])  # [batch_size, len_v, n_head * d_v]\n",
    "                return x\n",
    "            head = Lambda(reshape2)(head)\n",
    "        elif self.mode == 1:\n",
    "            heads = []; attns = []\n",
    "            for i in range(n_head):\n",
    "                qs = self.qs_layers[i](q)   \n",
    "                ks = self.ks_layers[i](k) \n",
    "                vs = self.vs_layers[i](v) \n",
    "                head, attn = self.attention(qs, ks, vs, mask)\n",
    "                heads.append(head); attns.append(attn)\n",
    "            head = Concatenate()(heads) if n_head > 1 else heads[0]\n",
    "            attn = Concatenate()(attns) if n_head > 1 else attns[0] \n",
    "        outputs = self.w_o(head)\n",
    "        outputs = Dropout(self.dropout)(outputs)\n",
    "        return outputs, attn    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward():\n",
    "    def __init__(self, d_hid, d_inner_hid, dropout=0.1):\n",
    "        self.w_1 = Conv1D(d_inner_hid, 1, activation='relu')\n",
    "        self.w_2 = Conv1D(d_hid, 1)\n",
    "        self.layer_norm = LayerNormalization()\n",
    "        self.dropout = Dropout(dropout)\n",
    "    def __call__(self, x):\n",
    "        output = self.w_1(x) \n",
    "        output = self.w_2(output)\n",
    "        output = self.dropout(output)\n",
    "        output = Add()([output, x])\n",
    "        return self.layer_norm(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer():\n",
    "    def __init__(self, d_model, d_inner_hid, n_head, dropout=0.1):\n",
    "        self.self_att_layer = MultiHeadAttention(n_head, d_model, dropout=dropout)\n",
    "        self.pos_ffn_layer  = PositionwiseFeedForward(d_model, d_inner_hid, dropout=dropout)\n",
    "        self.norm_layer = LayerNormalization()\n",
    "    def __call__(self, enc_input, mask=None):\n",
    "        output, slf_attn = self.self_att_layer(enc_input, enc_input, enc_input, mask=mask)\n",
    "        output = self.norm_layer(Add()([enc_input, output]))\n",
    "        output = self.pos_ffn_layer(output)\n",
    "        return output, slf_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer():\n",
    "    def __init__(self, d_model, d_inner_hid, n_head, dropout=0.1):\n",
    "        self.self_att_layer = MultiHeadAttention(n_head, d_model, dropout=dropout)\n",
    "        self.enc_att_layer  = MultiHeadAttention(n_head, d_model, dropout=dropout)\n",
    "        self.pos_ffn_layer  = PositionwiseFeedForward(d_model, d_inner_hid, dropout=dropout)\n",
    "        self.norm_layer1 = LayerNormalization()\n",
    "        self.norm_layer2 = LayerNormalization()\n",
    "    def __call__(self, dec_input, enc_output, self_mask=None, enc_mask=None, dec_last_state=None):\n",
    "        if dec_last_state is None: dec_last_state = dec_input\n",
    "        output, slf_attn = self.self_att_layer(dec_input, dec_last_state, dec_last_state, mask=self_mask)\n",
    "        x = self.norm_layer1(Add()([dec_input, output]))\n",
    "        output, enc_attn = self.enc_att_layer(x, enc_output, enc_output, mask=enc_mask)\n",
    "        x = self.norm_layer2(Add()([x, output]))\n",
    "        output = self.pos_ffn_layer(x)\n",
    "        return output, slf_attn, enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPosEncodingMatrix(max_len, d_emb):\n",
    "    pos_enc = np.array([\n",
    "        [pos / np.power(10000, 2 * (j // 2) / d_emb) for j in range(d_emb)] \n",
    "        if pos != 0 else np.zeros(d_emb) \n",
    "            for pos in range(max_len)\n",
    "            ])\n",
    "    pos_enc[1:, 0::2] = np.sin(pos_enc[1:, 0::2]) # dim 2i\n",
    "    pos_enc[1:, 1::2] = np.cos(pos_enc[1:, 1::2]) # dim 2i+1\n",
    "    return pos_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPadMask(q, k):\n",
    "    '''\n",
    "    shape: [B, Q, K]\n",
    "    '''\n",
    "    ones = K.expand_dims(K.ones_like(q, 'float32'), -1)\n",
    "    mask = K.cast(K.expand_dims(K.not_equal(k, 0), 1), 'float32')\n",
    "    mask = K.batch_dot(ones, mask, axes=[2,1])\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSubMask(s):\n",
    "    '''\n",
    "    shape: [B, Q, K], lower triangle because the i-th row should have i 1s.\n",
    "    '''\n",
    "    len_s = tf.shape(s)[1]\n",
    "    bs = tf.shape(s)[:1]\n",
    "    mask = K.cumsum(tf.eye(len_s, batch_shape=bs), 1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention():\n",
    "    def __init__(self, d_model, d_inner_hid, n_head, layers=6, dropout=0.1):\n",
    "        self.layers = [EncoderLayer(d_model, d_inner_hid, n_head, dropout) for _ in range(layers)]\n",
    "    def __call__(self, src_emb, src_seq, return_att=False, active_layers=999):\n",
    "        if return_att: atts = []\n",
    "        mask = Lambda(lambda x:K.cast(K.greater(x, 0), 'float32'))(src_seq)\n",
    "        x = src_emb\t\t\n",
    "        for enc_layer in self.layers[:active_layers]:\n",
    "            x, att = enc_layer(x, mask)\n",
    "            if return_att: atts.append(att)\n",
    "        return (x, atts) if return_att else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder():\n",
    "    def __init__(self, d_model, d_inner_hid, n_head, layers=6, dropout=0.1):\n",
    "        self.layers = [DecoderLayer(d_model, d_inner_hid, n_head, dropout) for _ in range(layers)]\n",
    "    def __call__(self, tgt_emb, tgt_seq, src_seq, enc_output, return_att=False, active_layers=999):\n",
    "        x = tgt_emb\n",
    "        self_pad_mask = Lambda(lambda x:GetPadMask(x, x))(tgt_seq)\n",
    "        self_sub_mask = Lambda(GetSubMask)(tgt_seq)\n",
    "        self_mask = Lambda(lambda x:K.minimum(x[0], x[1]))([self_pad_mask, self_sub_mask])\n",
    "        enc_mask = Lambda(lambda x:GetPadMask(x[0], x[1]))([tgt_seq, src_seq])\n",
    "        if return_att: self_atts, enc_atts = [], []\n",
    "        for dec_layer in self.layers[:active_layers]:\n",
    "            x, self_att, enc_att = dec_layer(x, enc_output, self_mask, enc_mask)\n",
    "            if return_att: \n",
    "                self_atts.append(self_att)\n",
    "                enc_atts.append(enc_att)\n",
    "        return (x, self_atts, enc_atts) if return_att else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderPerStep(Layer):\n",
    "    def __init__(self, decoder):\n",
    "        super().__init__()\n",
    "        self.layers = decoder.layers\n",
    "    def call(self, inputs):\n",
    "        (x, src_seq, enc_output), tgt_embs = inputs[:3], inputs[3:]\n",
    "        enc_mask = K.cast(K.greater(src_seq, 0), 'float32')\n",
    "        llen = tf.shape(tgt_embs[0])[1]\n",
    "        col_mask = K.cast(K.equal(K.cumsum(K.ones_like(tgt_embs[0], dtype='int32'), axis=1), llen), dtype='float32')\n",
    "        rs = [x]\n",
    "        for i, dec_layer in enumerate(self.layers):\n",
    "            tgt_emb = tgt_embs[i] + x * col_mask\n",
    "            x, _, _ = dec_layer(x, enc_output, enc_mask=enc_mask, dec_last_state=tgt_emb)\n",
    "            rs.append(x)\n",
    "        return rs\n",
    "    def compute_output_shape(self, ishape):\n",
    "        return [ishape[0] for _ in range(len(self.layers)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderPerStep(Layer):\n",
    "    def __init__(self, decoder):\n",
    "        super().__init__()\n",
    "        self.layers = decoder.layers\n",
    "    def call(self, inputs):\n",
    "        (x, src_seq, enc_output), tgt_embs = inputs[:3], inputs[3:]\n",
    "        enc_mask = K.cast(K.greater(src_seq, 0), 'float32')\n",
    "        llen = tf.shape(tgt_embs[0])[1]\n",
    "        col_mask = K.cast(K.equal(K.cumsum(K.ones_like(tgt_embs[0], dtype='int32'), axis=1), llen), dtype='float32')\n",
    "        rs = [x]\n",
    "        for i, dec_layer in enumerate(self.layers):\n",
    "            tgt_emb = tgt_embs[i] + x * col_mask\n",
    "            x, _, _ = dec_layer(x, enc_output, enc_mask=enc_mask, dec_last_state=tgt_emb)\n",
    "            rs.append(x)\n",
    "        return rs\n",
    "    def compute_output_shape(self, ishape):\n",
    "        return [ishape[0] for _ in range(len(self.layers)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadoutDecoderCell(Layer):\n",
    "    def __init__(self, o_word_emb, pos_emb, decoder, target_layer, **kwargs):\n",
    "        self.o_word_emb = o_word_emb\n",
    "        self.pos_emb = pos_emb\n",
    "        self.decoder = decoder\n",
    "        self.target_layer = target_layer\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, inputs, states, constants, training=None):\n",
    "        (tgt_curr_input, tgt_pos_input, dec_mask), dec_output = states[:3], list(states[3:])\n",
    "        enc_output, enc_mask = constants\n",
    "\n",
    "        time = K.max(tgt_pos_input)\n",
    "        col_mask = K.cast(K.equal(K.cumsum(K.ones_like(dec_mask), axis=1), time), dtype='int32')\n",
    "        dec_mask = dec_mask + col_mask\n",
    "\n",
    "        tgt_emb = self.o_word_emb(tgt_curr_input)\n",
    "        if self.pos_emb: tgt_emb = tgt_emb + self.pos_emb(tgt_pos_input, pos_input=True)\n",
    "\n",
    "        x = tgt_emb\n",
    "        xs = []\n",
    "        cc = K.cast(K.expand_dims(col_mask), dtype='float32')\n",
    "        for i, dec_layer in enumerate(self.decoder.layers):\n",
    "            dec_last_state = dec_output[i] * (1-cc) + tf.einsum('ijk,ilj->ilk', x, cc)\n",
    "            x, _, _ = dec_layer(x, enc_output, dec_mask, enc_mask, dec_last_state=dec_last_state)\n",
    "            xs.append(dec_last_state)\n",
    "\n",
    "        ff_output = self.target_layer(x)\n",
    "        out = K.cast(K.argmax(ff_output, -1), dtype='int32')\n",
    "        return out, [out, tgt_pos_input+1, dec_mask] + xs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferRNN(Layer):\n",
    "    def __init__(self, cell, return_sequences=False, go_backwards=False, **kwargs):\n",
    "        if not hasattr(cell, 'call'):\n",
    "            raise ValueError('`cell` should have a `call` method. ' 'The RNN was passed:', cell)\n",
    "        super().__init__(**kwargs)\n",
    "        self.cell = cell\n",
    "        self.return_sequences = return_sequences\n",
    "        self.go_backwards = go_backwards\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1], 1) if self.return_sequences else (input_shape[0], 1)\n",
    "            \n",
    "    def __call__(self, inputs, initial_state=None, constants=None, **kwargs):\n",
    "        if initial_state is not None:\n",
    "            kwargs['initial_state'] = initial_state\n",
    "        if constants is not None:\n",
    "            kwargs['constants'] = constants\n",
    "            self._num_constants = len(constants)\n",
    "        return super().__call__(inputs, **kwargs)\n",
    "\n",
    "    def call(self, inputs, mask=None, training=None, initial_state=None, constants=None):\n",
    "        if isinstance(inputs, list):\n",
    "            if self._num_constants is None: initial_state = inputs[1:]\n",
    "            else: initial_state = inputs[1:-self._num_constants]\n",
    "            inputs = inputs[0]\n",
    "        input_shape = K.int_shape(inputs)\n",
    "        timesteps = input_shape[1]\n",
    "\n",
    "        kwargs = {}\n",
    "        def step(inputs, states):\n",
    "            constants = states[-self._num_constants:]\n",
    "            states = states[:-self._num_constants]\n",
    "            return self.cell.call(inputs, states, constants=constants, **kwargs)\n",
    "\n",
    "        last_output, outputs, states = K.rnn(step, inputs, initial_state, constants=constants,\n",
    "                                                go_backwards=self.go_backwards,\n",
    "                                                mask=mask, unroll=False, input_length=timesteps)\n",
    "        output = outputs if self.return_sequences else last_output\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_batch_greedy(src_seq, encode_model, decode_model, start_mark, end_mark, max_len=128):\n",
    "    enc_ret = encode_model.predict_on_batch(src_seq)\n",
    "    bs = src_seq.shape[0]\n",
    "    target_one = np.zeros((bs, 1), dtype='int32')\n",
    "    target_one[:,0] = start_mark\n",
    "    d_model = decode_model.inputs[-1].shape[-1]\n",
    "    n_dlayers = len(decode_model.inputs) - 3\n",
    "    dec_outputs = [np.zeros((bs, 1, d_model)) for _ in range(n_dlayers)]\n",
    "    ended = [0 for x in range(bs)]\n",
    "    decoded_indexes = [[] for x in range(bs)]\n",
    "    for i in range(max_len-1):\n",
    "        outputs = decode_model.predict_on_batch([target_one, src_seq, enc_ret] + dec_outputs)\n",
    "        new_dec_outputs, output = outputs[:-1], outputs[-1]\n",
    "        for dec_output, new_out in zip(dec_outputs, new_dec_outputs): \n",
    "            dec_output[:,-1,:] = new_out[:,0,:]\n",
    "        dec_outputs = [np.concatenate([x, np.zeros_like(new_out)], axis=1) for x in dec_outputs]\n",
    "\n",
    "        sampled_indexes = np.argmax(output[:,0,:], axis=-1)\n",
    "        for ii, sampled_index in enumerate(sampled_indexes):\n",
    "            if sampled_index == end_mark: ended[ii] = 1\n",
    "            if not ended[ii]: decoded_indexes[ii].append(sampled_index)\n",
    "        if sum(ended) == bs: break\n",
    "        target_one[:,0] = sampled_indexes\n",
    "    return decoded_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_batch_beam_search(src_seq, topk, encode_model, decode_model, start_mark, end_mark, max_len=128, early_stop_mult=5):\n",
    "    N = src_seq.shape[0]\n",
    "    src_seq = src_seq.repeat(topk, 0)\n",
    "    enc_ret = encode_model.predict_on_batch(src_seq)\n",
    "    bs = src_seq.shape[0]\n",
    "\n",
    "    target_one = np.zeros((bs, 1), dtype='int32')\n",
    "    target_one[:,0] = start_mark\n",
    "    d_model = decode_model.inputs[-1].shape[-1]\n",
    "    n_dlayers = len(decode_model.inputs) - 3\n",
    "    dec_outputs = [np.zeros((bs, 1, d_model)) for _ in range(n_dlayers)]\n",
    "\n",
    "    final_results = []\n",
    "    decoded_indexes = [[] for x in range(bs)]\n",
    "    decoded_logps = [0] * bs\n",
    "    lastks = [1 for x in range(N)]\n",
    "    bests = {}\n",
    "    for i in range(max_len-1):\n",
    "        outputs = decode_model.predict_on_batch([target_one, src_seq, enc_ret] + dec_outputs)\n",
    "        new_dec_outputs, output = outputs[:-1], outputs[-1]\n",
    "        for dec_output, new_out in zip(dec_outputs, new_dec_outputs): \n",
    "            dec_output[:,-1,:] = new_out[:,0,:]\n",
    "\n",
    "        dec_outputs = [np.concatenate([x, np.zeros_like(new_out)], axis=1) for x in dec_outputs]\n",
    "\n",
    "        output = np.exp(output[:,0,:])\n",
    "        output = np.log(output / np.sum(output, -1, keepdims=True) + 1e-8)\n",
    "\n",
    "        next_dec_outputs = [x.copy() for x in dec_outputs]\n",
    "        next_decoded_indexes = [1 for x in range(bs)]\n",
    "\n",
    "        for ii in range(N):\n",
    "            base = ii * topk\n",
    "            cands = []\n",
    "            for k, wprobs in zip(range(lastks[ii]), output[base:,:]):\n",
    "                prev = base+k\n",
    "                if len(decoded_indexes[prev]) > 0 and decoded_indexes[prev][-1] == end_mark: continue\n",
    "                ind = np.argpartition(wprobs, -topk)[-topk:]\n",
    "                wsorted = [(k,x) for k,x in zip(ind, wprobs[ind])]\n",
    "                #wsorted = sorted(list(enumerate(wprobs)), key=lambda x:x[-1], reverse=True)   # slow\n",
    "                for wid, wp in wsorted[:topk]: \n",
    "                    wprob = decoded_logps[prev]+wp\n",
    "                    if wprob < bests.get(ii, -1e5) * early_stop_mult: continue\n",
    "                    cands.append( (prev, wid, wprob) )\n",
    "            cands.sort(key=lambda x:x[-1], reverse=True)\t\n",
    "            cands = cands[:topk]\n",
    "            lastks[ii] = len(cands)\n",
    "            for kk, zz in enumerate(cands):\n",
    "                prev, wid, wprob = zz\n",
    "                npos = base+kk\n",
    "                for k in range(len(next_dec_outputs)):\n",
    "                    next_dec_outputs[k][npos,:,:] = dec_outputs[k][prev]\n",
    "                target_one[npos,0] = wid\n",
    "                decoded_logps[npos] = wprob\n",
    "                next_decoded_indexes[npos] = decoded_indexes[prev].copy()\n",
    "                next_decoded_indexes[npos].append(wid)\n",
    "                if wid == end_mark:\n",
    "                    final_results.append( (ii, decoded_indexes[prev].copy(), wprob) ) \n",
    "                    if ii not in bests or wprob > bests[ii]: bests[ii] = wprob\n",
    "        if sum(lastks) == 0: break\n",
    "        dec_outputs = next_dec_outputs\n",
    "        decoded_indexes = next_decoded_indexes\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer:\n",
    "    def __init__(self, i_tokens, o_tokens, len_limit, d_model=256, \\\n",
    "                d_inner_hid=512, n_head=4, layers=2, dropout=0.1, \\\n",
    "                share_word_emb=False):\n",
    "        self.i_tokens = i_tokens\n",
    "        self.o_tokens = o_tokens\n",
    "        self.len_limit = len_limit\n",
    "        self.d_model = d_model\n",
    "        self.decode_model = None\n",
    "        self.readout_model = None\n",
    "        self.layers = layers\n",
    "        d_emb = d_model\n",
    "\n",
    "        self.src_loc_info = True\n",
    "\n",
    "        d_k = d_v = d_model // n_head\n",
    "        assert d_k * n_head == d_model and d_v == d_k\n",
    "\n",
    "        self.pos_emb = PosEncodingLayer(len_limit, d_emb) if self.src_loc_info else None\n",
    "\n",
    "        self.emb_dropout = Dropout(dropout)\n",
    "\n",
    "        self.i_word_emb = Embedding(i_tokens.num(), d_emb)\n",
    "        if share_word_emb: \n",
    "            assert i_tokens.num() == o_tokens.num()\n",
    "            self.o_word_emb = i_word_emb\n",
    "        else: self.o_word_emb = Embedding(o_tokens.num(), d_emb)\n",
    "\n",
    "        self.encoder = SelfAttention(d_model, d_inner_hid, n_head, layers, dropout)\n",
    "        self.decoder = Decoder(d_model, d_inner_hid, n_head, layers, dropout)\n",
    "        self.target_layer = TimeDistributed(Dense(o_tokens.num(), use_bias=False))\n",
    "\n",
    "    def compile(self, optimizer='adam', active_layers=999):\n",
    "        src_seq_input = Input(shape=(None,), dtype='int32')\n",
    "        tgt_seq_input = Input(shape=(None,), dtype='int32')\n",
    "\n",
    "        src_seq = src_seq_input\n",
    "        tgt_seq  = Lambda(lambda x:x[:,:-1])(tgt_seq_input)\n",
    "        tgt_true = Lambda(lambda x:x[:,1:])(tgt_seq_input)\n",
    "\n",
    "        src_emb = self.i_word_emb(src_seq)\n",
    "        tgt_emb = self.o_word_emb(tgt_seq)\n",
    "\n",
    "        if self.pos_emb: \n",
    "            src_emb = add_layer([src_emb, self.pos_emb(src_seq)])\n",
    "            tgt_emb = add_layer([tgt_emb, self.pos_emb(tgt_seq)])\n",
    "        src_emb = self.emb_dropout(src_emb)\n",
    "\n",
    "        enc_output = self.encoder(src_emb, src_seq, active_layers=active_layers)\n",
    "        dec_output = self.decoder(tgt_emb, tgt_seq, src_seq, enc_output, active_layers=active_layers)\t\n",
    "        final_output = self.target_layer(dec_output)\n",
    "\n",
    "        def get_loss(y_pred, y_true):\n",
    "            y_true = tf.cast(y_true, 'int32')\n",
    "            loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "            mask = tf.cast(tf.not_equal(y_true, 0), 'float32')\n",
    "            loss = tf.reduce_sum(loss * mask, -1) / tf.reduce_sum(mask, -1)\n",
    "            loss = K.mean(loss)\n",
    "            return loss\n",
    "\n",
    "        def get_accu(y_pred, y_true):\n",
    "            mask = tf.cast(tf.not_equal(y_true, 0), 'float32')\n",
    "            corr = K.cast(K.equal(K.cast(y_true, 'int32'), K.cast(K.argmax(y_pred, axis=-1), 'int32')), 'float32')\n",
    "            corr = K.sum(corr * mask, -1) / K.sum(mask, -1)\n",
    "            return K.mean(corr)\n",
    "\n",
    "        loss = get_loss(final_output, tgt_true)\n",
    "        self.ppl = K.exp(loss)\n",
    "        self.accu = get_accu(final_output, tgt_true)\n",
    "\n",
    "        self.model = Model([src_seq_input, tgt_seq_input], final_output)\n",
    "        self.model.add_loss([loss])\n",
    "\n",
    "        self.model.compile(optimizer, None)\n",
    "        self.model.metrics_names.append('ppl')\n",
    "        self.model.metrics_tensors.append(self.ppl)\n",
    "        self.model.metrics_names.append('accu')\n",
    "        self.model.metrics_tensors.append(self.accu)\n",
    "\n",
    "    def make_src_seq_matrix(self, input_seqs):\n",
    "        if type(input_seqs[0]) == type(''): input_seqs = [input_seqs]\n",
    "        maxlen = max(map(len, input_seqs))\n",
    "        src_seq = np.zeros((len(input_seqs), maxlen+3), dtype='int32')\n",
    "        src_seq[:,0] = self.i_tokens.startid()\n",
    "        for i, seq in enumerate(input_seqs):\n",
    "            for ii, z in enumerate(seq):\n",
    "                src_seq[i,1+ii] = self.i_tokens.id(z)\n",
    "            src_seq[i,1+len(seq)] = self.i_tokens.endid()\n",
    "        return src_seq\n",
    "\n",
    "    def make_readout_decode_model(self, max_output_len=32):\n",
    "        src_seq_input = Input(shape=(None,), dtype='int32')\n",
    "        tgt_start_input = Input(shape=(1,), dtype='int32')\n",
    "        src_seq = src_seq_input\n",
    "        enc_mask = Lambda(lambda x:K.cast(K.greater(x, 0), 'float32'))(src_seq)\n",
    "        src_emb = self.i_word_emb(src_seq)\n",
    "        if self.pos_emb: \n",
    "            src_emb = add_layer([src_emb, self.pos_emb(src_seq)])\n",
    "\n",
    "        src_emb = self.emb_dropout(src_emb)\n",
    "        enc_output = self.encoder(src_emb, src_seq)\n",
    "\n",
    "        tgt_emb = self.o_word_emb(tgt_start_input)\n",
    "        tgt_seq = Lambda(lambda x:K.repeat_elements(x, max_output_len, 1))(tgt_start_input)\n",
    "        rep_input = Lambda(lambda x:K.repeat_elements(x, max_output_len, 1))(tgt_emb)\n",
    "\n",
    "        cell = ReadoutDecoderCell(self.o_word_emb, self.pos_emb, self.decoder, self.target_layer)\n",
    "        final_output = InferRNN(cell, return_sequences=True)(rep_input, \n",
    "                initial_state=[tgt_start_input, K.ones_like(tgt_start_input), K.zeros_like(tgt_seq)] + \\\n",
    "                        [rep_input for _ in self.decoder.layers], \n",
    "                constants=[enc_output, enc_mask])\n",
    "        final_output = Lambda(lambda x:K.squeeze(x, -1))(final_output)\n",
    "        self.readout_model = Model([src_seq_input, tgt_start_input], final_output)\n",
    "    \n",
    "    def decode_sequence_readout_x(self, X, batch_size=32, max_output_len=64):\n",
    "        if self.readout_model is None: self.make_readout_decode_model(max_output_len)\n",
    "        target_seq = np.zeros((X.shape[0], 1), dtype='int32')\n",
    "        target_seq[:,0] = self.o_tokens.startid()\n",
    "        ret = self.readout_model.predict([X, target_seq], batch_size=batch_size, verbose=1)\n",
    "        return ret\n",
    "\n",
    "    def generate_sentence(self, rets, delimiter=''):\n",
    "        sents = []\n",
    "        for x in rets:\n",
    "            end_pos = min([i for i, z in enumerate(x) if z == self.o_tokens.endid()]+[len(x)])\n",
    "            rsent = [*map(self.o_tokens.token, x)][:end_pos]\n",
    "            sents.append(delimiter.join(rsent))\n",
    "        return sents\n",
    "\n",
    "    def decode_sequence_readout(self, input_seqs, delimiter=''):\n",
    "        if self.readout_model is None: self.make_readout_decode_model()\n",
    "        src_seq = self.make_src_seq_matrix(input_seqs)\n",
    "        target_seq = np.zeros((src_seq.shape[0],1), dtype='int32')\n",
    "        target_seq[:,0] = self.o_tokens.startid()\n",
    "        rets = self.readout_model.predict([src_seq, target_seq])\n",
    "        rets = self.generate_sentence(rets, delimiter)\n",
    "        if type(input_seqs[0]) is type('') and len(rets) == 1: rets = rets[0]\n",
    "        return rets\n",
    "\n",
    "    def make_fast_decode_model(self):\n",
    "        src_seq_input = Input(shape=(None,), dtype='int32')\n",
    "        src_emb = self.i_word_emb(src_seq_input)\n",
    "        if self.pos_emb: src_emb = add_layer([src_emb, self.pos_emb(src_seq_input)])\n",
    "        src_emb = self.emb_dropout(src_emb)\n",
    "        enc_output = self.encoder(src_emb, src_seq_input)\n",
    "        self.encode_model = Model(src_seq_input, enc_output)\n",
    "\n",
    "        self.decoder_pre_step = DecoderPerStep(self.decoder)\n",
    "\n",
    "        src_seq_input = Input(shape=(None,), dtype='int32')\n",
    "        tgt_one_input = Input(shape=(1,), dtype='int32')\n",
    "        enc_ret_input = Input(shape=(None, self.d_model))\n",
    "        dec_ret_inputs = [Input(shape=(None, self.d_model)) for _ in self.decoder.layers]\n",
    "\n",
    "        tgt_pos = Lambda(lambda x:tf.shape(x)[1])(dec_ret_inputs[0])\n",
    "\n",
    "        tgt_one = self.o_word_emb(tgt_one_input)\n",
    "        if self.pos_emb: tgt_one = add_layer([tgt_one, self.pos_emb(tgt_pos, pos_input=True)])\n",
    "\n",
    "        dec_outputs = self.decoder_pre_step([tgt_one, src_seq_input, enc_ret_input]+dec_ret_inputs)\t\n",
    "        final_output = self.target_layer(dec_outputs[-1])\n",
    "\n",
    "        self.decode_model = Model([tgt_one_input, src_seq_input, enc_ret_input]+dec_ret_inputs, \n",
    "                            dec_outputs[:-1]+[final_output])\n",
    "\n",
    "    def decode_sequence_fast(self, input_seqs, batch_size=32, delimiter='', verbose=0):\n",
    "        if self.decode_model is None: self.make_fast_decode_model()\n",
    "        src_seq = self.make_src_seq_matrix(input_seqs)\n",
    "\n",
    "        start_mark, end_mark = self.o_tokens.startid(), self.o_tokens.endid()\n",
    "        max_len = self.len_limit\n",
    "        encode_model = self.encode_model\n",
    "        decode_model = self.decode_model\n",
    "\n",
    "        decode_batch = lambda x: decode_batch_greedy(x, encode_model, decode_model, start_mark, end_mark, max_len)\n",
    "\n",
    "        rets = []\n",
    "        rng = range(0, src_seq.shape[0], batch_size)\n",
    "        if verbose and src_seq.shape[0] > batch_size: rng = tqdm(rng, total=len(rng))\n",
    "        for iter in rng:\n",
    "            rets.extend( decode_batch(src_seq[iter:iter+batch_size]) )\n",
    "            \n",
    "        rets = [delimiter.join(list(map(self.o_tokens.token, ret))) for ret in rets]\n",
    "        if type(input_seqs[0]) is type('') and len(rets) == 1: rets = rets[0]\n",
    "        return rets\n",
    "\n",
    "    def beam_search(self, input_seqs, topk=5, batch_size=8, length_penalty=1, delimiter='', verbose=0):\n",
    "        if self.decode_model is None: self.make_fast_decode_model()\n",
    "        src_seq = self.make_src_seq_matrix(input_seqs)\n",
    "\n",
    "        start_mark, end_mark = self.o_tokens.startid(), self.o_tokens.endid()\n",
    "        max_len = self.len_limit\n",
    "        encode_model = self.encode_model\n",
    "        decode_model = self.decode_model\n",
    "\n",
    "        decode_batch = lambda x: decode_batch_beam_search(x, topk, encode_model, decode_model,\n",
    "                                                    start_mark, end_mark, max_len)\n",
    "        \n",
    "        rets = {}\n",
    "        rng = range(0, src_seq.shape[0], batch_size)\n",
    "        if verbose and src_seq.shape[0] > batch_size: rng = tqdm(rng, total=len(rng))\n",
    "\n",
    "        for iter in rng:\n",
    "            for i, x, y in decode_batch(src_seq[iter:iter+batch_size]):\n",
    "                rets.setdefault(iter+i, []).append( (x, y/np.power(len(x)+1, length_penalty)) )\n",
    "        rets = {x:sorted(ys,key=lambda x:x[-1], reverse=True) for x,ys in rets.items()}\n",
    "        rets = [rets[i] for i in range(len(rets))]\n",
    "\n",
    "        rets = [[(delimiter.join(list(map(self.o_tokens.token, x))), y) for x, y in r] for r in rets]\n",
    "        if type(input_seqs[0]) is type('') and len(rets) == 1: rets = rets[0]\n",
    "        return rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PosEncodingLayer:\n",
    "    def __init__(self, max_len, d_emb):\n",
    "        self.pos_emb_matrix = Embedding(max_len, d_emb, trainable=False, \\\n",
    "                           weights=[GetPosEncodingMatrix(max_len, d_emb)])\n",
    "    def get_pos_seq(self, x):\n",
    "        mask = K.cast(K.not_equal(x, 0), 'int32')\n",
    "        pos = K.cumsum(K.ones_like(x, 'int32'), 1)\n",
    "        return pos * mask\n",
    "    def __call__(self, seq, pos_input=False):\n",
    "        x = seq\n",
    "        if not pos_input: x = Lambda(self.get_pos_seq)(x)\n",
    "        return self.pos_emb_matrix(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddPosEncoding:\n",
    "    def __call__(self, x):\n",
    "        _, max_len, d_emb = K.int_shape(x)\n",
    "        pos = GetPosEncodingMatrix(max_len, d_emb)\n",
    "        x = Lambda(lambda x:x+pos)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRSchedulerPerStep(Callback):\n",
    "    def __init__(self, d_model, warmup=4000):\n",
    "        self.basic = d_model**-0.5\n",
    "        self.warm = warmup**-1.5\n",
    "        self.step_num = 0\n",
    "    def on_batch_begin(self, batch, logs = None):\n",
    "        self.step_num += 1\n",
    "        lr = self.basic * min(self.step_num**-0.5, self.step_num*self.warm)\n",
    "        K.set_value(self.model.optimizer.lr, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_layer = Lambda(lambda x:x[0]+x[1], output_shape=lambda x:x[0])\n",
    "# use this because keras may get wrong shapes with Add()([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QANet_ConvBlock:\n",
    "    def __init__(self, dim, n_conv=2, kernel_size=7, dropout=0.1):\n",
    "        self.convs = [SeparableConv1D(dim, kernel_size, activation='relu', padding='same') for _ in range(n_conv)]\n",
    "        self.norm = LayerNormalization()\n",
    "        self.dropout = Dropout(dropout)\n",
    "    def __call__(self, x):\n",
    "        for i in range(len(self.convs)):\n",
    "            z = self.norm(x)\n",
    "            if i % 2 == 0: z = self.dropout(z)\n",
    "            z = self.convs[i](z)\n",
    "            x = add_layer([x, z])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QANet_Block:\n",
    "    def __init__(self, dim, n_head, n_conv, kernel_size, dropout=0.1, add_pos=True):\n",
    "        self.conv = QANet_ConvBlock(dim, n_conv=n_conv, kernel_size=kernel_size, dropout=dropout)\n",
    "        self.self_att = MultiHeadAttention(n_head=n_head, d_model=dim, \n",
    "                                            d_k=dim//n_head, d_v=dim//n_head, \n",
    "                                            dropout=dropout, use_norm=False)\n",
    "        self.feed_forward = PositionwiseFeedForward(dim, dim, dropout=dropout)\n",
    "        self.norm = LayerNormalization()\n",
    "        self.add_pos = add_pos\n",
    "    def __call__(self, x, mask):\n",
    "        if self.add_pos: x = AddPosEncoding()(x)\n",
    "        x = self.conv(x)\n",
    "        z = self.norm(x)\n",
    "        z, _ = self.self_att(z, z, z, mask)\n",
    "        x = add_layer([x, z])\n",
    "        z = self.norm(x)\n",
    "        z = self.feed_forward(z)\n",
    "        x = add_layer([x, z])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QANet_Encoder:\n",
    "    def __init__(self, dim=128, n_head=8, n_conv=2, n_block=1, kernel_size=7, dropout=0.1, add_pos=True):\n",
    "        self.dim = dim\n",
    "        self.n_block = n_block\n",
    "        self.conv_first = SeparableConv1D(dim, 1, padding='same')\n",
    "        self.enc_block = QANet_Block(dim, n_head=n_head, n_conv=n_conv, kernel_size=kernel_size, \n",
    "                                    dropout=dropout, add_pos=add_pos)\n",
    "    def __call__(self, x, mask):\n",
    "        if K.int_shape(x)[-1] != self.dim:\n",
    "            x = self.conv_first(x)\n",
    "        for i in range(self.n_block):\n",
    "            x = self.enc_block(x, mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4368\n"
     ]
    }
   ],
   "source": [
    "with open('../Data/Preprocessed/reply.txt', 'r') as reply_file:\n",
    "    reply_whole = reply_file.read()\n",
    "with open('../Data/Preprocessed/title.txt', 'r') as title_file:\n",
    "    title_whole = title_file.read()\n",
    "    \n",
    "# 전체 텍스트의 마지막 빈 문장 제거 및 텍스트 리스트로 값 저장\n",
    "replies_bundle = reply_whole.rstrip().split('\\n')\n",
    "titles = title_whole.rstrip().split('\\n')\n",
    "\n",
    "# 파일에서 불러온 텍스트의 개수 확인\n",
    "assert(len(titles) == len(replies_bundle))\n",
    "\n",
    "index_for_delete = []\n",
    "for i in range(len(titles)):\n",
    "    if titles[i] == '':\n",
    "        index_for_delete.append(i)\n",
    "\n",
    "for index in index_for_delete:\n",
    "    del titles[index]\n",
    "    del replies_bundle[index]\n",
    "assert(len(titles) == len(replies_bundle))\n",
    "\n",
    "# 베댓(첫번째 댓글)만 따로 리스트로 만들기\n",
    "for i in range(len(replies_bundle)):\n",
    "    replies_bundle[i] = eval(replies_bundle[i])\n",
    "replies = [reply_bundle[0]['text'] for reply_bundle in replies_bundle]\n",
    "assert(len(titles) == len(replies))\n",
    "\n",
    "# 총 데이터의 갯수\n",
    "num_data = len(titles)\n",
    "print(num_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 데이터 이렇게 사용하면돼!\n",
    "mode = 'best' # all or best\n",
    "assert(mode in ['all', 'best'])\n",
    "\n",
    "with open('../Data/Preprocessed/titles-'+mode+'.txt', 'r') as reply_file:\n",
    "    titles = eval(reply_file.read())\n",
    "with open('../Data/Preprocessed/replies-'+mode+'.txt', 'r') as title_file:\n",
    "    replies = eval(title_file.read())\n",
    "# 유효성 검사\n",
    "assert(len(reply_whole) == len(title_whole))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['일을 저렇게 열심히 해보지', 'kbs 앵커 니놈부터 과한 돈을 받고 있지, 귀족노조가 금수저임. ', '지 발등을 지가 찍은거죠. 1박에 15만원이면 지방에서 웬만한 호텔 1박 요금 아닌가? ', '결국은 종량제 봉투도 바뀌게되겠죠. 모순을 지적하기 전에 시행에 더 의미를 뒀으면 합니다. 전에는 이것조차 안 했었잖아요', '대한민국모든 공무원중에제일존경합니다', '맞는말했네. 일덜하고 돈 더벌수 없어, 그치만 우리 문모씨는 일덜하고 돈 더준다는데 사상교육좀 시켜줘라. ', '바오밥 나무마저 쓰러지다니 지구온난화가 얼마나 심한지 감이 잡히네요, 이런 기사들을 볼때마다 지구온난화가 얼마나 심한지 다시 생각하게 되고 환경에 신경쓰게 되는 것 같네요, 어서 빨리 지구온난화가 괜찮아지면 좋겠네요. ', '보통 국민들의 핵심은 결국 먹고 사는 문제인데 문정부는 그걸 모르는것 같다. 현실은 무시하고 자기들의 이상향만이 제일 중요한건지, 진짜 보통의 국민들과 어려운 사람들을 위한 상식이 통하는 정부라고 기대했는데 오히려 갈수록 더 어렵게 만들고 있네, 지금 하는 정책들을 보면 공무원 계열 및 소위 대기업 귀족 근로자들을 위해서는 이상적인 정책이다. 근데 문정부의 정책에 맞추면 결국 제일 큰 타격은 진짜 중소업체랑 영세자영업자들인데, 이러면 빈부 격차는 훨씬 더 커질테고, 진짜 내 앞에 있으면 면전에다 대고 계란한판을 풀스윙으로. ', '음식에 동전을 넣다니. ', '플라이바이는 중력도움 비행이 아니고 스윙바이가 중력 도움 비행입니다. 플라이바이는 그냥 관측 목적으로 천체 가까이 스쳐지나가는 걸 말합니다. 중력도움, 즉 스윙바이는 항로나 속도를 변경할 목적으로 천체 곁을 지나가는건데 당연히 행성급의 중력을 가진 천체라야 가능한 얘기죠. ']\n"
     ]
    }
   ],
   "source": [
    "print(titles[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(titles, replies, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data length:  11593\n",
      "test data length:  1289\n"
     ]
    }
   ],
   "source": [
    "print(\"train data length: \", len(x_train))\n",
    "print(\"test data length: \", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ti2re_whole.txt', 'w') as f:\n",
    "    for t, r in zip(titles, replies):\n",
    "        f.write(t+'\\t'+r+'\\n')\n",
    "\n",
    "with open('ti2re.txt', 'w') as f:\n",
    "    for t, r in zip(x_train, y_train):\n",
    "        f.write(t+'\\t'+r+'\\n')\n",
    "\n",
    "with open('ti2re_valid.txt', 'w') as f:\n",
    "    for t, r in zip(x_test, y_test):\n",
    "        f.write(t+'\\t'+r+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataloader as dd\n",
    "from keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq 1 words: 76094\n",
      "seq 2 words: 29503\n",
      "seq 1 words: 76098\n",
      "seq 2 words: 29507\n",
      "train shapes: (11593, 85) (11593, 16)\n",
      "valid shapes: (1289, 82) (1289, 15)\n"
     ]
    }
   ],
   "source": [
    "itokens, otokens = dd.MakeS2SDict('ti2re.txt', dict_file='ti2re_word.txt', min_freq=1)\n",
    "Xtrain, Ytrain = dd.MakeS2SData('ti2re.txt', itokens, otokens, h5_file='ti2re.h5')\n",
    "Xvalid, Yvalid = dd.MakeS2SData('ti2re_valid.txt', itokens, otokens, h5_file='ti2re_valid.h5')\n",
    "\n",
    "print('seq 1 words:', itokens.num())\n",
    "print('seq 2 words:', otokens.num())\n",
    "print('train shapes:', Xtrain.shape, Ytrain.shape)\n",
    "print('valid shapes:', Xvalid.shape, Yvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 256\n",
    "s2s = Transformer(itokens, otokens, len_limit=70, d_model=d_model, d_inner_hid=512, \\\n",
    "                    n_head=8, layers=2, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfile = 'ti2re_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = LRSchedulerPerStep(d_model, 4000) \n",
    "model_saver = ModelCheckpoint(mfile, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "new model\n"
     ]
    }
   ],
   "source": [
    "s2s.compile(Adam(0.001, 0.9, 0.98, epsilon=1e-9))\n",
    "try: s2s.model.load_weights(mfile)\n",
    "except: print('\\n\\nnew model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11593 samples, validate on 1289 samples\n",
      "Epoch 1/10\n",
      "11593/11593 [==============================] - 23s 2ms/step - loss: 5.5145 - ppl: 252.6483 - accu: 0.2213 - val_loss: 7.7242 - val_ppl: 2365.7160 - val_accu: 0.1521\n",
      "Epoch 2/10\n",
      "11593/11593 [==============================] - 23s 2ms/step - loss: 5.0488 - ppl: 158.3114 - accu: 0.2625 - val_loss: 7.6484 - val_ppl: 2206.2351 - val_accu: 0.1648\n",
      "Epoch 3/10\n",
      "11593/11593 [==============================] - 23s 2ms/step - loss: 4.5399 - ppl: 95.6595 - accu: 0.3145 - val_loss: 7.7999 - val_ppl: 2640.5043 - val_accu: 0.1826\n",
      "Epoch 4/10\n",
      "11593/11593 [==============================] - 23s 2ms/step - loss: 3.9850 - ppl: 54.9995 - accu: 0.3757 - val_loss: 7.6361 - val_ppl: 2268.9484 - val_accu: 0.2094\n",
      "Epoch 5/10\n",
      "11593/11593 [==============================] - 23s 2ms/step - loss: 3.4034 - ppl: 30.8047 - accu: 0.4553 - val_loss: 7.6013 - val_ppl: 2221.9712 - val_accu: 0.2447\n",
      "Epoch 6/10\n",
      "11593/11593 [==============================] - 23s 2ms/step - loss: 2.8614 - ppl: 17.8656 - accu: 0.5458 - val_loss: 7.6860 - val_ppl: 2464.7886 - val_accu: 0.2656\n",
      "Epoch 7/10\n",
      "11593/11593 [==============================] - 23s 2ms/step - loss: 2.3706 - ppl: 10.9374 - accu: 0.6287 - val_loss: 7.5557 - val_ppl: 2197.6346 - val_accu: 0.2853\n",
      "Epoch 8/10\n",
      "11593/11593 [==============================] - 23s 2ms/step - loss: 1.9381 - ppl: 7.0748 - accu: 0.6932 - val_loss: 7.8251 - val_ppl: 2936.3612 - val_accu: 0.2921\n",
      "Epoch 9/10\n",
      "11593/11593 [==============================] - 23s 2ms/step - loss: 1.6135 - ppl: 5.0851 - accu: 0.7350 - val_loss: 8.0334 - val_ppl: 3701.9543 - val_accu: 0.2937\n",
      "Epoch 10/10\n",
      "11593/11593 [==============================] - 23s 2ms/step - loss: 1.4027 - ppl: 4.1044 - accu: 0.7575 - val_loss: 8.0853 - val_ppl: 3879.8713 - val_accu: 0.2969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fee0b5442b0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#s2s.model.summary()\n",
    "s2s.model.fit([Xtrain, Ytrain], None, batch_size=64, epochs=10, \\\n",
    "                validation_data=([Xvalid, Yvalid], None), \\\n",
    "                callbacks=[lr_scheduler, model_saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제목: 분리수거 하면 뭐하는데 재사용하는 비용이 그냥 생산하는비용보다 많이 들고 감당 안되니깐 바다에 몰래 쳐 버려서 거북이 콧구멍에 빨대박히는데 내가 라면스프 봉지까지 분리배출 했었는데 그뉴스보고 지금까지 내가 뭘한건가 싶더라 그래놓고 분리수거 안하면 수거 안해간다 하고 벌금낸다 하고있나 대책도 없고 가이드라인도 존나 없어서 인터넷 검색해서 내놓는데 어딘 종이컵은 종이류라하고 어딘 종이컵은 코팅되서 재활용 못한다하고, 분리수거만 시키면 뭐하냐고 진심 딥빡이네\n",
      "댓글: 바다거북 뱃속에 쓰레기 가득 해양 생태계 위협\n",
      "\n",
      "\n",
      "제목: 필리핀 말레이시아 들도 쓰레기 가저 가라고 항의하는데 ? 왜 우린 중국한테 미세먼지 가저 가라고 항의 조차 안하는거냐 ? 아니왜 중국산 미세 먼지를 한국산이라고 합니까 정부는 ? \n",
      "댓글: 트럼프 명령, 대치국면 끝내고 협상국면으로? \n",
      "\n",
      "\n",
      "제목: 우리동네 셀프 세차장 돈맛 보더니 물 나오는 시간도 줄이고 요금도 지들 멋대로 올렸더라\n",
      "댓글: 김학의 사건 재수사 급물살 특임검사 임명에 무게 \n",
      "\n",
      "\n",
      "제목: 그래서 나온게 공산주의임. 근데 그게 훨씬더 씹7창이었다는 사실은 말안하네ㅋㅋ 역사의 흑사병임 이놈의 가진자꺼 뺏자는 마인드는. \n",
      "댓글: 여야 도로친박당 vs 내로남불 활개 한국당 침묵\n",
      "\n",
      "\n",
      "제목: 저두 현재 사회복지사로 근무중이지만, 쓸때없는 서류 작업이 넘 않아, 미칠 지경입니다, 평가를. 위한 서류들, 야근에, 토. 일까지 나와서 근무를 합니다, 그런다고, 대상자에 대한 서비스가 좋아지나요? 그건 절대. 아닙니다, 쓸때없는 서류부터 정리 해야합니다. \n",
      "댓글: 김학의 재수사 급물살 특임검사 특임검사 임명에 무게 \n",
      "\n",
      "\n",
      "제목: 솔직히 우리나라 올겨울 따뜻 한거다\n",
      "댓글: 426일 굴뚝농성 파인텍 노사 교섭 극적 타결\n",
      "\n",
      "\n",
      "제목: 나쁜놈과 더나쁜놈의 싸움이군. \n",
      "댓글: 러 모스크바, 기록적 폭설 항공 운항 지연 취소 잇따라 \n",
      "\n",
      "\n",
      "제목: 경찰이 뒷배봐준건 쏘 옥 드갔넹. \n",
      "댓글: 검찰, 양승태 전 대법원장 구속영장 발부 \n",
      "\n",
      "\n",
      "제목: 문죄인아, 우리도 쓸데없는 공무원좀 그만 증원하고 그 돈으로 이공계좀 투자하쟈. 당장의 이윤은 못 내더라도 장기적인 관점에서 국가가 발전하려면 이공계가 강해야되. 세계적은 투자가 짐 로저스 말했다. 젊은이들의 꿈이 공무원인 나라는 투자 가치가 없다 \n",
      "댓글: 하루 전화만 50통 사생활 없어진 송파 헬리오시티\n",
      "\n",
      "\n",
      "제목: 베트남이 번영이라, 남베트남 주도 통일이였음 지금 부귀영화는 수십년전에 진작에 누렸을걸\n",
      "댓글: 김학의 사건 재수사 가능성? , 소환 불응 뒤 두문불출\n",
      "\n",
      "\n",
      "제목: 이래서 중소다닐바에 알바2개하는게 돈 더잘범. 영원한직장? ㅋㅋ그딴게어딨어\n",
      "댓글: 426일 굴뚝농성 파인텍 노사 교섭 극적 타결\n",
      "\n",
      "\n",
      "제목: 나쁜 상황이 아니기를 기도합니다\n",
      "댓글: 경찰, 외국 연수 중 가이드 폭행 예천군의원 수사\n",
      "\n",
      "\n",
      "제목: 그러면서 손혜원은 투기가 아니라고? 이건무슨논리야 ? 미친 정부 국민들이 바보인줄 아닌냐\n",
      "댓글: 경찰, 조재범 전 코치 특별수사팀 구성\n",
      "\n",
      "\n",
      "제목: 접속하면 프로그램을 깔게 하는 순간에 보안이고 뭐고 다 의미가 없어진다. 액티브엑스 종속 덕분에 세계 최하의 보안수준 이야. 그나마 한국어라는 로컬 언어벽이 있어서 국제적으로 제외되어 왔지\n",
      "댓글: 택시 카풀 대타협기구 더딘 성과 전현희 지속 노력중 \n",
      "\n",
      "\n",
      "제목: 역사기록도 부실 복원도 부실 참\n",
      "댓글: 검찰, 양승태 전 대법원장 구속영장 발부 \n",
      "\n",
      "\n",
      "제목: 지들이 이명박근혜 찍어줘서 공약대로 경상도에 핵발전소, 지열발전소 지어준건데, 뭘 어쩌라고요? 탓할게 있다면 이명박근혜에 몰빵해준 자기들 손가락을 탓해야 하는거 아님? \n",
      "댓글: 택시 카풀 사회적 대타협기구 출범 상생방안 모색 나서\n",
      "\n",
      "\n",
      "제목: 배스보다는 덜한 물고기인가 ? \n",
      "댓글: 검찰, 양승태 전 대법원장 구속영장 발부 \n",
      "\n",
      "\n",
      "제목: 이 기사를 보니 미국 그랜드캐년에서 사고당한 사람의 동생이 생각나네 구찌 벨트 구찌 신발신고 자기들은 서민이라 돈없다고 치료비 정부에서 해줘야된다고. \n",
      "댓글: , 놀가지 색출령 조직지도부 이탈리아 급파\n",
      "\n",
      "\n",
      "제목: 외우기쉽게 7일로통일하자 슁바것\n",
      "댓글: 러 모스크바, 기록적 폭설 항공 운항 지연 취소 잇따라 \n",
      "\n",
      "\n",
      "제목: 기사 읽어보니 공수처 설치가 답이네요, 야당은 협조하세요\n",
      "댓글: 설 앞두고 구제역 확산하나 안성서 하루만에 또 확진 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ljqpy\n",
    "valids = ljqpy.LoadCSV('ti2re_valid.txt')\n",
    "en = [x[0].split() for x in valids[:100]]\n",
    "rets = s2s.decode_sequence_readout(en, delimiter=' ')\n",
    "\n",
    "for i in range(20):\n",
    "    print('제목: {}'.format(valids[i][0]))\n",
    "    print('댓글: {}'.format(rets[i]))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
