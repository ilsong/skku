{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model_body = Word2Vec.load('word2vec_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_total' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8080a7b71686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_total' is not defined"
     ]
    }
   ],
   "source": [
    "print(model_body.wv.index2word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "tag = Komoran()\n",
    "f = open('../Data/Preprocessed/body.txt', encoding=\"utf8\")\n",
    "sentences = f.read().strip().split('\\n')\n",
    "f.close()\n",
    "\n",
    "error = []\n",
    "result = []\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    try:\n",
    "        result.append(tag.morphs(sentence))\n",
    "    except:\n",
    "        result.append(None)\n",
    "        error.append(i)\n",
    "        print(\"Error! \", i)\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../Data/Preprocessed/Morphs/body.txt', \"w\", encoding=\"utf-8\")\n",
    "f.write(str(result))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../Data/Preprocessed/reply.txt', encoding=\"utf-8\")\n",
    "sentences = [sentence[0]['text'] for sentence in list(map(eval, f.read().strip().split(\"\\n\")))]\n",
    "f.close()\n",
    "\n",
    "error_reply = []\n",
    "result_reply = []\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    try:\n",
    "        result_reply.append(tag.morphs(sentence))\n",
    "    except:\n",
    "        result_reply.append(None)\n",
    "        error_reply.append(i)\n",
    "        print(\"Error! \", i)\n",
    "print(len(result_reply))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_total = error+error_reply\n",
    "error_total.sort(reverse=True)\n",
    "\n",
    "for error_idx in error_total:\n",
    "    del result[error_idx]\n",
    "    del result_reply[error_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../Data/Preprocessed/Morphs/body-noerror.txt', \"w\", encoding=\"utf-8\")\n",
    "f.write(str(result))\n",
    "f.close()\n",
    "f = open('../Data/Preprocessed/Morphs/reply-noerror.txt', \"w\", encoding=\"utf-8\")\n",
    "f.write(str(result_reply))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Error가 제거된 데이터 Read\n",
    "\n",
    "f = open('../Data/Preprocessed/Morphs/body-noerror.txt', 'r', encoding='utf-8')\n",
    "result = eval(f.read())\n",
    "f.close()\n",
    "\n",
    "f = open('../Data/Preprocessed/Morphs/reply-noerror.txt', 'r', encoding='utf-8')\n",
    "result_reply = eval(f.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4357\n",
      "4357\n"
     ]
    }
   ],
   "source": [
    "print(len(result))\n",
    "print(len(result_reply))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "### Make vector list to all text of each words\n",
    "\n",
    "x_data, y_data = [], []\n",
    "result_len = len(result)\n",
    "\n",
    "for sentence_idx in range(result_len):\n",
    "    vector_x, vector_y = [], []\n",
    "    \n",
    "    for word in result[sentence_idx]:\n",
    "        try:\n",
    "            vector_x.append(model_total.wv[word])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    for word in result_reply[sentence_idx]:\n",
    "        try:\n",
    "            vector_y.append(model_total.wv[word])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    x_data.append(vector_x)\n",
    "    y_data.append(vector_y)\n",
    "    \n",
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x data shape:  (4357,)\n",
      "y data shape:  (4357,)\n"
     ]
    }
   ],
   "source": [
    "### shape (# of data, # of word, length of embedding vector)\n",
    "\n",
    "print(\"x data shape: \", x_data.shape)\n",
    "print(\"y data shape: \", y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess= tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#for y in y_data[0]:\n",
    "#    print(model_total.wv.most_similar(positive=[y], topn=1))\n",
    "x_data_maxlen = 500\n",
    "y_data_maxlen = 50\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras import backend as K\n",
    "x_data = sequence.pad_sequences(x_data, padding='post', maxlen=x_data_maxlen, dtype=K.floatx())\n",
    "y_data = sequence.pad_sequences(y_data, padding='pre', maxlen=y_data_maxlen, dtype=K.floatx())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4357, 500, 100)\n",
      "(4357, 50, 100)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "print(x_data[0][325])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Dropout, Input\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "target_shape = y_train.shape[1:]\n",
    "latent_dim = 128\n",
    "\n",
    "encoder_inputs = Input(shape=input_shape)\n",
    "#encoder_inputs = BatchNormalization()(encoder_inputs)\n",
    "encoder = LSTM(latent_dim, return_sequences=True, return_state=True, kernel_initializer='zeros', recurrent_initializer='zeros')\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=target_shape)\n",
    "#decoder_inputs = BatchNormalization()(decoder_inputs)\n",
    "decoder = LSTM(latent_dim, return_sequences=True, return_state=True, kernel_initializer='zeros', recurrent_initializer='zeros')\n",
    "decoder_outputs, _, _ = decoder(decoder_inputs, initial_state = encoder_states)\n",
    "decoder_dense = Dense(target_shape[1], activation='tanh')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_outputs)\n",
    "rmsprop = RMSprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='hinge', optimizer=rmsprop, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ 바꿔가면서 해보세요 ######################################\n",
    "num_epochs = 20\n",
    "mini_batch_size = 64\n",
    "######################################################################################\n",
    "history = model.fit([x_data, y_data], y_data, epochs=num_epochs, batch_size=mini_batch_size, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 50\n",
    "b = model.predict([x_data[idx:idx+1], np.zeros_like(y_data[0:1])])\n",
    "for i in range(10):\n",
    "    print(model_total.wv.most_similar(positive=[y_data[idx][i]], topn=1))\n",
    "print()\n",
    "for i in range(10):\n",
    "    print(model_total.wv.most_similar(positive=[b[0][i]], topn=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
