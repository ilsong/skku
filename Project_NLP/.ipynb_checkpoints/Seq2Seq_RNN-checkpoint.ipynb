{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15628871823566907279\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7754258842\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 492126894879896594\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "import sys, os\n",
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess= tf.Session(config=config)\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print (device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the data txt file on disk.\n",
    "title_path = 'title.txt'\n",
    "reply_path = 'reply.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "with open(title_path, 'r', encoding='utf-8') as f:\n",
    "    titles = f.read().strip().split(\"\\n\")\n",
    "with open(reply_path, 'r', encoding='utf-8') as f:\n",
    "    replies = eval(f.read().strip()) #[eval(reply) for reply in f.read().strip().split(\"\\n\")] --> 원본데이터용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 댓글 text가 비어있는거 삭제\n",
    "error = []\n",
    "\n",
    "for i, reply in enumerate(replies):\n",
    "    for j, sub_reply in enumerate(reply):\n",
    "        if sub_reply['text'] == \"\":\n",
    "            print(\"error on: \", sub_reply, i, j)\n",
    "            error.append((i,j))\n",
    "for i,j in list(reversed(error)):\n",
    "    del replies[i][j]\n",
    "\n",
    "if error:\n",
    "    with open(reply_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(str(replies))\n",
    "        \n",
    "print(\"total title len: \", len(titles))\n",
    "print(\"total reply len: \", len(replies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "tag = Komoran()\n",
    "\n",
    "# 형태소 분석\n",
    "# 댓글 길이와 갯수 제한\n",
    "title_morphs = []\n",
    "reply_morphs = []\n",
    "title_morphs_set = set()\n",
    "reply_morphs_set = set()\n",
    "max_reply_num = 5\n",
    "max_reply_len = 50\n",
    "\n",
    "for title in titles:\n",
    "    morphs = tag.morphs(title)\n",
    "    title_morphs.append(morphs)\n",
    "    for morph in morphs:\n",
    "        title_morphs_set.add(morph)\n",
    "    \n",
    "for reply in replies:\n",
    "    subreply_morphs = []\n",
    "    sub_reply_num = 0\n",
    "    \n",
    "    for sub_reply in reply:\n",
    "        if sub_reply_num >= max_reply_num:\n",
    "            break\n",
    "            \n",
    "        morphs = tag.morphs(sub_reply['text'])\n",
    "        if len(morphs) > max_reply_len-2: # start와 end tag고려\n",
    "            continue\n",
    "            \n",
    "        subreply_morphs.append(morphs)\n",
    "        sub_reply_num += 1\n",
    "        for morph in morphs:\n",
    "            reply_morphs_set.add(morph)\n",
    "            \n",
    "    reply_morphs.append(subreply_morphs)\n",
    "\n",
    "# 형태소 분석시 붙어서 나와가지고, 따로 넣어줌\n",
    "reply_morphs_set.add('<start>')\n",
    "reply_morphs_set.add('<end>')\n",
    "        \n",
    "print(\"title morphs num: \", len(title_morphs_set))\n",
    "print(\"reply morphs num: \", len(reply_morphs_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 집합 저장\n",
    "with open('title-morphs_set', 'w', encoding='utf-8') as f:\n",
    "    f.write(str(sorted(list(title_morphs_set))))\n",
    "with open('reply-morphs_set', 'w', encoding='utf-8') as f:\n",
    "    f.write(str(sorted(list(reply_morphs_set))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 변환된거 저장\n",
    "with open('title-morphs', 'w', encoding='utf-8') as f:\n",
    "    f.write(str(title_morphs))\n",
    "with open('reply-morphs', 'w', encoding='utf-8') as f:\n",
    "    f.write(str(reply_morphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 변환 후, 여기부터 불러쓰기\n",
    "from konlpy.tag import Komoran\n",
    "tag = Komoran()\n",
    "\n",
    "max_reply_num = 5\n",
    "max_reply_len = 50\n",
    "\n",
    "title_morphs_set = []\n",
    "reply_morphs_set = []\n",
    "title_morphs = []\n",
    "reply_morphs = []\n",
    "\n",
    "with open('title-morphs_set', 'r', encoding='utf-8') as f:\n",
    "    title_morphs_set = eval(f.read())\n",
    "with open('reply-morphs_set', 'r', encoding='utf-8') as f:\n",
    "    reply_morphs_set = eval(f.read())\n",
    "with open('title-morphs', 'r', encoding='utf-8') as f:\n",
    "    title_morphs = eval(f.read())\n",
    "with open('reply-morphs', 'r', encoding='utf-8') as f:\n",
    "    reply_morphs = eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples:  16818\n",
      "num_test_samples:  1869\n",
      "num_encoder_tokens:  7802\n",
      "num_decoder_tokens:  17697\n",
      "max_encoder_seq_length:  31\n",
      "max_decoder_seq_length:  50\n"
     ]
    }
   ],
   "source": [
    "# 제목과 댓글text 1:1 매칭 & pos 태깅\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "for idx, reply in enumerate(reply_morphs):\n",
    "    for sub_reply in reply:\n",
    "        train_x.append(title_morphs[idx])\n",
    "        train_y.append(['<start>'] + sub_reply + ['<end>'])\n",
    "\n",
    "num_total = len(train_x)\n",
    "train_x, test_x = train_x[:int(num_total*0.9)], train_x[int(num_total*0.9):]\n",
    "train_y, test_y = train_y[:int(num_total*0.9)], train_y[int(num_total*0.9):]\n",
    "\n",
    "num_samples = len(train_x)\n",
    "num_test_samples = len(test_x)\n",
    "title_morphs_set = sorted(list(title_morphs_set))\n",
    "reply_morphs_set = sorted(list(reply_morphs_set))\n",
    "num_encoder_tokens = len(title_morphs_set)\n",
    "num_decoder_tokens = len(reply_morphs_set)\n",
    "max_encoder_seq_length = max([len(x) for x in train_x])\n",
    "max_decoder_seq_length = max([len(y) for y in train_y])\n",
    "\n",
    "print(\"num_samples: \", num_samples)\n",
    "print(\"num_test_samples: \", num_test_samples)\n",
    "print(\"num_encoder_tokens: \", num_encoder_tokens)\n",
    "print(\"num_decoder_tokens: \", num_decoder_tokens)\n",
    "print(\"max_encoder_seq_length: \", max_encoder_seq_length)\n",
    "print(\"max_decoder_seq_length: \", max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(morph, i) for i, morph in enumerate(title_morphs_set)])\n",
    "target_token_index = dict(\n",
    "    [(morph, i) for i, morph in enumerate(reply_morphs_set)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros((num_samples, max_encoder_seq_length), dtype=\"float32\")\n",
    "decoder_input_data = np.zeros((num_samples, max_decoder_seq_length), dtype=\"float32\")\n",
    "decoder_target_data = np.zeros((num_samples, max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "\n",
    "encoder_test_data = np.zeros((num_test_samples, max_encoder_seq_length), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(zip(train_x, train_y)):\n",
    "    for t, morph in enumerate(x):\n",
    "        encoder_input_data[i, t] = input_token_index[morph]\n",
    "    for t, morph in enumerate(y):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t] = target_token_index[morph]\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[morph]] = 1.\n",
    "            \n",
    "for i, x in enumerate(test_x):\n",
    "    for t, morph in enumerate(x):\n",
    "        encoder_test_data[i, t] = input_token_index[morph]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_data shape:  (16818, 31)\n",
      "decoder_input_data shape:  (16818, 50)\n",
      "decoder_target_data shape:  (16818, 50, 17697)\n",
      "encoder_test_data shape:  (1869, 31)\n"
     ]
    }
   ],
   "source": [
    "print(\"encoder_input_data shape: \", encoder_input_data.shape)\n",
    "print(\"decoder_input_data shape: \", decoder_input_data.shape)\n",
    "print(\"decoder_target_data shape: \", decoder_target_data.shape)\n",
    "\n",
    "print(\"encoder_test_data shape: \", encoder_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 10  # Number of epochs to train for.\n",
    "latent_dim = 64  # Latent dimensionality of the encoding space.\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_input_layer = Input(shape=(None,))\n",
    "enc_embedding_layer = Embedding(num_encoder_tokens, latent_dim)\n",
    "enc_input = enc_embedding_layer(encoder_input_layer)\n",
    "enc_normalization_layer = BatchNormalization()\n",
    "enc_normalized_input = enc_normalization_layer(enc_input)\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(enc_normalized_input)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_input_layer = Input(shape=(None,))\n",
    "dec_embedding_layer = Embedding(num_decoder_tokens, latent_dim)\n",
    "dec_input = dec_embedding_layer(decoder_input_layer)\n",
    "dec_normalization_layer = BatchNormalization()\n",
    "dec_normalized_input = dec_normalization_layer(dec_input)\n",
    "decoder = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder(dec_normalized_input, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_output_layer = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 64)     499328      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 64)     1132608     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, 64)     256         embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, 64)     256         embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 64), (None,  33024       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 64), ( 33024       batch_normalization_2[0][0]      \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 17697)  1150305     lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,848,801\n",
      "Trainable params: 2,848,545\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_input_layer, decoder_input_layer], decoder_output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f608cc4c0b8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "plot_model(model,'model_image.png', show_layer_names=False, show_shapes=True)\n",
    "model_img=mpimg.imread('model_image.png')\n",
    "plt.figure(figsize=[10,50])\n",
    "plt.imshow(model_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15136 samples, validate on 1682 samples\n",
      "Epoch 1/10\n",
      "15136/15136 [==============================] - 177s 12ms/step - loss: 2.6883 - acc: 0.0701 - val_loss: 2.4978 - val_acc: 0.0782\n",
      "Epoch 2/10\n",
      "15136/15136 [==============================] - 158s 10ms/step - loss: 2.4009 - acc: 0.0933 - val_loss: 2.4529 - val_acc: 0.0833\n",
      "Epoch 3/10\n",
      "15136/15136 [==============================] - 159s 10ms/step - loss: 2.2943 - acc: 0.1031 - val_loss: 2.4454 - val_acc: 0.0851\n",
      "Epoch 4/10\n",
      "15136/15136 [==============================] - 158s 10ms/step - loss: 2.2244 - acc: 0.1104 - val_loss: 2.4491 - val_acc: 0.0881\n",
      "Epoch 5/10\n",
      "15136/15136 [==============================] - 158s 10ms/step - loss: 2.1717 - acc: 0.1161 - val_loss: 2.4665 - val_acc: 0.0887\n",
      "Epoch 6/10\n",
      "15136/15136 [==============================] - 158s 10ms/step - loss: 2.1252 - acc: 0.1214 - val_loss: 2.4798 - val_acc: 0.0892\n",
      "Epoch 7/10\n",
      "15136/15136 [==============================] - 300s 20ms/step - loss: 2.0903 - acc: 0.1264 - val_loss: 2.4968 - val_acc: 0.0881\n",
      "Epoch 8/10\n",
      "15136/15136 [==============================] - 281s 19ms/step - loss: 2.0623 - acc: 0.1301 - val_loss: 2.5106 - val_acc: 0.0878\n",
      "Epoch 9/10\n",
      "15136/15136 [==============================] - 271s 18ms/step - loss: 2.0392 - acc: 0.1336 - val_loss: 2.5339 - val_acc: 0.0880\n",
      "Epoch 10/10\n",
      "15136/15136 [==============================] - 164s 11ms/step - loss: 2.0152 - acc: 0.1372 - val_loss: 2.5480 - val_acc: 0.0878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:888: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 64) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "# Run training\n",
    "rmsprop = optimizers.RMSprop(lr=0.01)\n",
    "model.compile(optimizer=rmsprop, loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.1)\n",
    "# Save model\n",
    "model.save('s2s.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 64)          499328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, 64)          256       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                [(None, 64), (None, 64),  33024     \n",
      "=================================================================\n",
      "Total params: 532,608\n",
      "Trainable params: 532,480\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 64)     1132608     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, 64)     256         embedding_2[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 64), ( 33024       batch_normalization_2[1][0]      \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 17697)  1150305     lstm_2[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,316,193\n",
      "Trainable params: 2,316,065\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_input_layer, encoder_states)\n",
    "encoder_model.summary()\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "infer_input = dec_embedding_layer(decoder_input_layer)\n",
    "infer_normalized_input = dec_normalization_layer(infer_input)\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder(infer_normalized_input, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_input_layer] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "decoder_model.summary()\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_morph_index = dict(\n",
    "    (i, morph) for morph, i in input_token_index.items())\n",
    "reverse_target_morph_index = dict(\n",
    "    (i, morph) for morph, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['<start>']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = []\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_morph = reverse_target_morph_index[sampled_token_index]\n",
    "        decoded_sentence.append(sampled_morph)\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_morph == '<end>' or\n",
    "           len(decoded_sentence) > max_reply_len-2):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: [['정밀', '안전', '진단', '놓', '고', '4', '개월', '째', '다툼', '…', '방치', '되', 'ㄴ', '균열', '건물']]\n",
      "Decoded sentence: ['왜', 'ㄴ', ',', '3', '년', '이', '면', '되', 'ㄹ', '것', '이', '다', '.', '<end>']\n",
      "-\n",
      "Input sentence: [['英', '영하', '15', '도', '에', '폭설', '…', '항공', '·', '철도', '운행', '차질', '에', '학교', '휴업', '속출']]\n",
      "Decoded sentence: ['문재인', '이', '있', '으면', '좋', '겠', '다', '.', '<end>']\n",
      "-\n",
      "Input sentence: [['야생동물', '밀렵', '에', '불법', '벌목', '까지', '…', '백두대간', '‘', '몸살', '’']]\n",
      "Decoded sentence: ['수소', '차', '충전', '소', '는', '왜', '오르', '고', ',', '내', '덕', '도', '많이', '보내', '어야', '하', 'ㄴ다', '.', '<end>']\n",
      "-\n",
      "Input sentence: [['야생동물', '밀렵', '에', '불법', '벌목', '까지', '…', '백두대간', '‘', '몸살', '’']]\n",
      "Decoded sentence: ['수소', '차', '충전', '소', '는', '왜', '오르', '고', ',', '내', '덕', '도', '많이', '보내', '어야', '하', 'ㄴ다', '.', '<end>']\n",
      "-\n",
      "Input sentence: [['\"', \"'\", '피해자', '답', 'ㅁ', \"'\", '요구', '하', '아서', 'ㄴ', '안', '되', '어', '\"', '…', \"'\", '성', '이', 'ㄴ지', '감수성', \"'\", '판단', '잇따르', 'ㄹ', '듯']]\n",
      "Decoded sentence: ['한국', '은', '왜', '이렇', '게', '되', '었', '다', '.', '<end>']\n",
      "-\n",
      "Input sentence: [['설', '연휴', '하늘', '길', '은', '‘', '만석', '’', '…', '명절', '일평균', '이용객', '최다']]\n",
      "Decoded sentence: ['문재인', '이', '있', '으면', '좋', '겠', '다', '.', '<end>']\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(0, 30, 5):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index+1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', train_x[seq_index: seq_index + 1])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: [['2월', '소비', '심리', '3', '개월', '째', '상승', '…', '1년', '뒤', '집값', '전망', '최악']]\n",
      "Decoded sentence: ['518', '유공자', '명단', '공개', '하', '면', '되', 'ㄴ다', '.', '<end>']\n",
      "-\n",
      "Input sentence: [['“', '3년', '뒤', '적', '폐', '몰리', 'ㄹ라', '”', '…', '웅크리', '는', '공직', '사회']]\n",
      "Decoded sentence: ['이', '게', '나라', '냐', '?', '<end>']\n",
      "-\n",
      "Input sentence: [['브렉시트', '연기?…투스크', '\"', '합리', '적', '결정', '\"', 'vs', '메이', '\"', '해결책', '아냐', '\"', '(', '종합', ')']]\n",
      "Decoded sentence: ['한국', '은', '왜', '이렇', '게', '되', '었', '다', '.', '<end>']\n",
      "-\n",
      "Input sentence: [['안희정', '법정', '구속', '등', '180', '도', '뒤집히', 'ㄴ', '판결', ',', '사법부', '불신', '부추기', '어']]\n",
      "Decoded sentence: ['삼가', '고인', '의', '명복', '을', '비', 'ㅂ니다', '.', '<end>']\n",
      "-\n",
      "Input sentence: [[\"'\", '피부', '촉촉', \"'\", '바', '디', '미스트', ',', '4', '개', '제품', '서', \"'\", '알레르기', '성분', \"'\"]]\n",
      "Decoded sentence: ['내', '가', '왜', '이렇', '게', '되', 'ㄴ', '것', '이', '다', '.', '<end>']\n",
      "-\n",
      "Input sentence: [['맘', '카페', '서', '“', '○○', '병원', '좋', '던데요', '”', '…', '알', '고', '보', '니', '가짜', '광고']]\n",
      "Decoded sentence: ['이', '나라', '는', '왜', '이렇', '게', '되', '었', '다', '.', '<end>']\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(0, 30, 5):\n",
    "    input_seq = encoder_test_data[seq_index: seq_index+1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    input_sentence = [morph for morph in test_x[seq_index]]\n",
    "    print('-')\n",
    "    print('Input sentence:', test_x[seq_index: seq_index + 1])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded sentence: ['부산', '까지', '중국', '발', '미세먼지', '가', '아', '지', '었', '으면', '좋', '겠', '다', '<end>']\n"
     ]
    }
   ],
   "source": [
    "custom_input = tag.morphs('문재인 가나다라 트럼프')\n",
    "custom_input_seq = []\n",
    "for morph in custom_input:\n",
    "    try: custom_input_seq.append(input_token_index[morph])\n",
    "    except: pass\n",
    "custom_input_seq = custom_input_seq + [0]*(max_encoder_seq_length - len(custom_input_seq))\n",
    "decoded_sentence = decode_sequence(custom_input_seq)\n",
    "print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
