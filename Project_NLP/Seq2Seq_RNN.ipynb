{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17099746119153261046\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7916630836\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8947178731259729044\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "import sys, os\n",
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess= tf.Session(config=config)\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print (device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the data txt file on disk.\n",
    "title_path = 'title.txt'\n",
    "reply_path = 'reply.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "with open(title_path, 'r', encoding='utf-8') as f:\n",
    "    titles = f.read().strip().split(\"\\n\")\n",
    "with open(reply_path, 'r', encoding='utf-8') as f:\n",
    "    replies = eval(f.read().strip()) #[eval(reply) for reply in f.read().strip().split(\"\\n\")] --> 원본데이터용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total title len:  4055\n",
      "total reply len:  4055\n"
     ]
    }
   ],
   "source": [
    "# 댓글 text가 비어있는거 삭제\n",
    "error = []\n",
    "\n",
    "for i, reply in enumerate(replies):\n",
    "    for j, sub_reply in enumerate(reply):\n",
    "        if sub_reply['text'] == \"\":\n",
    "            print(\"error on: \", sub_reply, i, j)\n",
    "            error.append((i,j))\n",
    "for i,j in list(reversed(error)):\n",
    "    del replies[i][j]\n",
    "\n",
    "if error:\n",
    "    with open(reply_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(str(replies))\n",
    "        \n",
    "print(\"total title len: \", len(titles))\n",
    "print(\"total reply len: \", len(replies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title morphs num:  7802\n",
      "reply morphs num:  21170\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "tag = Komoran()\n",
    "\n",
    "# 형태소 분석\n",
    "# 댓글 길이와 갯수 제한\n",
    "title_morphs = []\n",
    "reply_morphs = []\n",
    "title_morphs_set = set()\n",
    "reply_morphs_set = set()\n",
    "max_reply_num = 5\n",
    "max_reply_len = 100\n",
    "\n",
    "for title in titles:\n",
    "    morphs = tag.morphs(title)\n",
    "    title_morphs.append(morphs)\n",
    "    for morph in morphs:\n",
    "        title_morphs_set.add(morph)\n",
    "    \n",
    "for reply in replies:\n",
    "    subreply_morphs = []\n",
    "    sub_reply_num = 0\n",
    "    \n",
    "    for sub_reply in reply:\n",
    "        if sub_reply_num >= max_reply_num:\n",
    "            break\n",
    "            \n",
    "        morphs = tag.morphs(sub_reply['text'])\n",
    "        if len(morphs) > max_reply_len-2: # start와 end tag고려\n",
    "            continue\n",
    "            \n",
    "        subreply_morphs.append(morphs)\n",
    "        sub_reply_num += 1\n",
    "        for morph in morphs:\n",
    "            reply_morphs_set.add(morph)\n",
    "            \n",
    "    reply_morphs.append(subreply_morphs)\n",
    "\n",
    "# 형태소 분석시 붙어서 나와가지고, 따로 넣어줌\n",
    "reply_morphs_set.add('<start>')\n",
    "reply_morphs_set.add('<end>')\n",
    "        \n",
    "print(\"title morphs num: \", len(title_morphs_set))\n",
    "print(\"reply morphs num: \", len(reply_morphs_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 집합 저장\n",
    "with open('title-morphs_set', 'w', encoding='utf-8') as f:\n",
    "    f.write(str(sorted(list(title_morphs_set))))\n",
    "with open('reply-morphs_set', 'w', encoding='utf-8') as f:\n",
    "    f.write(str(sorted(list(reply_morphs_set))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 변환된거 저장\n",
    "with open('title-morphs', 'w', encoding='utf-8') as f:\n",
    "    f.write(str(title_morphs))\n",
    "with open('reply-morphs', 'w', encoding='utf-8') as f:\n",
    "    f.write(str(reply_morphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 변환 후, 여기부터 불러쓰기\n",
    "from konlpy.tag import Komoran\n",
    "tag = Komoran()\n",
    "\n",
    "max_reply_num = 5\n",
    "max_reply_len = 100\n",
    "\n",
    "title_morphs_set = []\n",
    "reply_morphs_set = []\n",
    "title_morphs = []\n",
    "reply_morphs = []\n",
    "\n",
    "with open('title-morphs_set', 'r', encoding='utf-8') as f:\n",
    "    title_morphs_set = eval(f.read())\n",
    "with open('reply-morphs_set', 'r', encoding='utf-8') as f:\n",
    "    reply_morphs_set = eval(f.read())\n",
    "with open('title-morphs', 'r', encoding='utf-8') as f:\n",
    "    title_morphs = eval(f.read())\n",
    "with open('reply-morphs', 'r', encoding='utf-8') as f:\n",
    "    reply_morphs = eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples:  18045\n",
      "num_test_samples:  2006\n",
      "num_encoder_tokens:  7802\n",
      "num_decoder_tokens:  21170\n",
      "max_encoder_seq_length:  31\n",
      "max_decoder_seq_length:  100\n"
     ]
    }
   ],
   "source": [
    "# 제목과 댓글text 1:1 매칭 & pos 태깅\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "for idx, reply in enumerate(reply_morphs):\n",
    "    for sub_reply in reply:\n",
    "        train_x.append(title_morphs[idx])\n",
    "        train_y.append(['<start>'] + sub_reply + ['<end>'])\n",
    "\n",
    "num_total = len(train_x)\n",
    "train_x, test_x = train_x[:int(num_total*0.9)], train_x[int(num_total*0.9):]\n",
    "train_y, test_y = train_y[:int(num_total*0.9)], train_y[int(num_total*0.9):]\n",
    "\n",
    "num_samples = len(train_x)\n",
    "num_test_samples = len(test_x)\n",
    "title_morphs_set = sorted(list(title_morphs_set))\n",
    "reply_morphs_set = sorted(list(reply_morphs_set))\n",
    "num_encoder_tokens = len(title_morphs_set)\n",
    "num_decoder_tokens = len(reply_morphs_set)\n",
    "max_encoder_seq_length = max([len(x) for x in train_x])\n",
    "max_decoder_seq_length = max([len(y) for y in train_y])\n",
    "\n",
    "print(\"num_samples: \", num_samples)\n",
    "print(\"num_test_samples: \", num_test_samples)\n",
    "print(\"num_encoder_tokens: \", num_encoder_tokens)\n",
    "print(\"num_decoder_tokens: \", num_decoder_tokens)\n",
    "print(\"max_encoder_seq_length: \", max_encoder_seq_length)\n",
    "print(\"max_decoder_seq_length: \", max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(morph, i) for i, morph in enumerate(title_morphs_set)])\n",
    "target_token_index = dict(\n",
    "    [(morph, i) for i, morph in enumerate(reply_morphs_set)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros((num_samples, max_encoder_seq_length), dtype=\"float32\")\n",
    "decoder_input_data = np.zeros((num_samples, max_decoder_seq_length), dtype=\"float32\")\n",
    "decoder_target_data = np.zeros((num_samples, max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "\n",
    "encoder_test_data = np.zeros((num_test_samples, max_encoder_seq_length), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(zip(train_x, train_y)):\n",
    "    for t, morph in enumerate(x):\n",
    "        encoder_input_data[i, t] = input_token_index[morph]\n",
    "    for t, morph in enumerate(y):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t] = target_token_index[morph]\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[morph]] = 1.\n",
    "            \n",
    "for i, x in enumerate(test_x):\n",
    "    for t, morph in enumerate(x):\n",
    "        encoder_test_data[i, t] = input_token_index[morph]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_data shape:  (18045, 31)\n",
      "decoder_input_data shape:  (18045, 100)\n",
      "decoder_target_data shape:  (18045, 100, 21170)\n",
      "encoder_test_data shape:  (2006, 31)\n"
     ]
    }
   ],
   "source": [
    "print(\"encoder_input_data shape: \", encoder_input_data.shape)\n",
    "print(\"decoder_input_data shape: \", decoder_input_data.shape)\n",
    "print(\"decoder_target_data shape: \", decoder_target_data.shape)\n",
    "\n",
    "print(\"encoder_test_data shape: \", encoder_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 10  # Number of epochs to train for.\n",
    "latent_dim = 64  # Latent dimensionality of the encoding space.\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_input_layer = Input(shape=(None,))\n",
    "enc_embedding_layer = Embedding(num_encoder_tokens, latent_dim)\n",
    "enc_input = enc_embedding_layer(encoder_input_layer)\n",
    "enc_normalization_layer = BatchNormalization()\n",
    "enc_normalized_input = enc_normalization_layer(enc_input)\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(enc_normalized_input)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_input_layer = Input(shape=(None,))\n",
    "dec_embedding_layer = Embedding(num_decoder_tokens, latent_dim)\n",
    "dec_input = dec_embedding_layer(decoder_input_layer)\n",
    "dec_normalization_layer = BatchNormalization()\n",
    "dec_normalized_input = dec_normalization_layer(dec_input)\n",
    "decoder = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder(dec_normalized_input, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_output_layer = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 64)     499328      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 64)     1354880     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, 64)     256         embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, 64)     256         embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 64), (None,  33024       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 64), ( 33024       batch_normalization_2[0][0]      \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 21170)  1376050     lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,296,818\n",
      "Trainable params: 3,296,562\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_input_layer, decoder_input_layer], decoder_output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8c08849978>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "plot_model(model,'model_image.png', show_layer_names=False, show_shapes=True)\n",
    "model_img=mpimg.imread('model_image.png')\n",
    "plt.figure(figsize=[10,50])\n",
    "plt.imshow(model_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16240 samples, validate on 1805 samples\n",
      "Epoch 1/10\n",
      "  448/16240 [..............................] - ETA: 7:31 - loss: 2.5221 - acc: 0.0056 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-83a533db052b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m           validation_split=0.1)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# Save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m's2s.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "# Run training\n",
    "rmsprop = optimizers.RMSprop(lr=0.01)\n",
    "model.compile(optimizer=rmsprop, loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.1)\n",
    "# Save model\n",
    "model.save('s2s.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_input_layer, encoder_states)\n",
    "encoder_model.summary()\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "infer_input = dec_embedding_layer(decoder_input_layer)\n",
    "infer_normalized_input = dec_normalization_layer(infer_input)\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder(infer_normalized_input, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_input_layer] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "decoder_model.summary()\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_morph_index = dict(\n",
    "    (i, morph) for morph, i in input_token_index.items())\n",
    "reverse_target_morph_index = dict(\n",
    "    (i, morph) for morph, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['<start>']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = []\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_morph = reverse_target_morph_index[sampled_token_index]\n",
    "        decoded_sentence.append(sampled_morph)\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_morph == '<end>' or\n",
    "           len(decoded_sentence) > max_reply_len-2):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq_index in range(0, 30, 5):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index+1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', train_x[seq_index: seq_index + 1])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq_index in range(0, 30, 5):\n",
    "    input_seq = encoder_test_data[seq_index: seq_index+1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('제목:', ' '.join(test_x[seq_index]))\n",
    "    print('댓글:', ' '.join(decoded_sentence[:-1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_input = tag.morphs('문재인 가나다라 트럼프')\n",
    "custom_input_seq = []\n",
    "for morph in custom_input:\n",
    "    try: custom_input_seq.append(input_token_index[morph])\n",
    "    except: pass\n",
    "custom_input_seq = custom_input_seq + [0]*(max_encoder_seq_length - len(custom_input_seq))\n",
    "decoded_sentence = decode_sequence(custom_input_seq)\n",
    "print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
