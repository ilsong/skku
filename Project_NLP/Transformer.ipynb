{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1311719552454423282\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7917938279\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16817898922756713908\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:81:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess= tf.Session(config=config)\n",
    "\n",
    "import sys\n",
    "from tensorflow.python.client import device_lib\n",
    "print (device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from keras.initializers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from tqdm import tqdm\n",
    "    from dataloader import TokenList, pad_to_longest\n",
    "    # for transformer\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(Layer):\n",
    "    def __init__(self, eps=1e-6, **kwargs):\n",
    "        self.eps = eps\n",
    "        super(LayerNormalization, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:], initializer=Ones(), trainable=True)\n",
    "        self.beta = self.add_weight(name='beta', shape=input_shape[-1:], initializer=Zeros(), trainable=True)\n",
    "        super(LayerNormalization, self).build(input_shape)\n",
    "    def call(self, x):\n",
    "        mean = K.mean(x, axis=-1, keepdims=True)\n",
    "        std = K.std(x, axis=-1, keepdims=True)\n",
    "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention():\n",
    "    def __init__(self, attn_dropout=0.1):\n",
    "        self.dropout = Dropout(attn_dropout)\n",
    "    def __call__(self, q, k, v, mask):\n",
    "        temper = tf.sqrt(tf.cast(tf.shape(k)[-1], dtype='float32'))\n",
    "        attn = Lambda(lambda x:K.batch_dot(x[0],x[1], axes=[2,2])/temper)([q,k])\n",
    "        if mask is not None:\n",
    "            mmask = Lambda(lambda x:(-1e+9)*(1.-K.cast(x, 'float32')))(mask)\n",
    "            attn = Add()([attn, mmask])\n",
    "        attn = Activation('softmax')(attn)\n",
    "        attn = self.dropout(attn)\n",
    "        output = Lambda(lambda x:K.batch_dot(x[0], x[1]))([attn, v])\n",
    "        return output, attn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention():\n",
    "    # mode 0 - big martixes, faster; mode 1 - more clear implementation\n",
    "    def __init__(self, n_head, d_model, dropout, mode=0):\n",
    "        self.mode = mode\n",
    "        self.n_head = n_head\n",
    "        self.d_k = self.d_v = d_k = d_v = d_model // n_head\n",
    "        self.dropout = dropout\n",
    "        if mode == 0:\n",
    "            self.qs_layer = Dense(n_head*d_k, use_bias=False)\n",
    "            self.ks_layer = Dense(n_head*d_k, use_bias=False)\n",
    "            self.vs_layer = Dense(n_head*d_v, use_bias=False)\n",
    "        elif mode == 1:\n",
    "            self.qs_layers = []\n",
    "            self.ks_layers = []\n",
    "            self.vs_layers = []\n",
    "            for _ in range(n_head):\n",
    "                self.qs_layers.append(TimeDistributed(Dense(d_k, use_bias=False)))\n",
    "                self.ks_layers.append(TimeDistributed(Dense(d_k, use_bias=False)))\n",
    "                self.vs_layers.append(TimeDistributed(Dense(d_v, use_bias=False)))\n",
    "        self.attention = ScaledDotProductAttention()\n",
    "        self.w_o = TimeDistributed(Dense(d_model))  \n",
    "    def __call__(self, q, k, v, mask=None):\n",
    "        d_k, d_v = self.d_k, self.d_v\n",
    "        n_head = self.n_head    \n",
    "        if self.mode == 0:\n",
    "            qs = self.qs_layer(q)  # [batch_size, len_q, n_head*d_k]\n",
    "            ks = self.ks_layer(k)\n",
    "            vs = self.vs_layer(v)   \n",
    "            def reshape1(x):\n",
    "                s = tf.shape(x)   # [batch_size, len_q, n_head * d_k]\n",
    "                x = tf.reshape(x, [s[0], s[1], n_head, s[2]//n_head])\n",
    "                x = tf.transpose(x, [2, 0, 1, 3])  \n",
    "                x = tf.reshape(x, [-1, s[1], s[2]//n_head])  # [n_head * batch_size, len_q, d_k]\n",
    "                return x\n",
    "            qs = Lambda(reshape1)(qs)\n",
    "            ks = Lambda(reshape1)(ks)\n",
    "            vs = Lambda(reshape1)(vs)   \n",
    "            if mask is not None:\n",
    "                mask = Lambda(lambda x:K.repeat_elements(x, n_head, 0))(mask)\n",
    "            head, attn = self.attention(qs, ks, vs, mask=mask)  \n",
    "\n",
    "            def reshape2(x):\n",
    "                s = tf.shape(x)   # [n_head * batch_size, len_v, d_v]\n",
    "                x = tf.reshape(x, [n_head, -1, s[1], s[2]]) \n",
    "                x = tf.transpose(x, [1, 2, 0, 3])\n",
    "                x = tf.reshape(x, [-1, s[1], n_head*d_v])  # [batch_size, len_v, n_head * d_v]\n",
    "                return x\n",
    "            head = Lambda(reshape2)(head)\n",
    "        elif self.mode == 1:\n",
    "            heads = []; attns = []\n",
    "            for i in range(n_head):\n",
    "                qs = self.qs_layers[i](q)   \n",
    "                ks = self.ks_layers[i](k) \n",
    "                vs = self.vs_layers[i](v) \n",
    "                head, attn = self.attention(qs, ks, vs, mask)\n",
    "                heads.append(head); attns.append(attn)\n",
    "            head = Concatenate()(heads) if n_head > 1 else heads[0]\n",
    "            attn = Concatenate()(attns) if n_head > 1 else attns[0] \n",
    "        outputs = self.w_o(head)\n",
    "        outputs = Dropout(self.dropout)(outputs)\n",
    "        return outputs, attn    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward():\n",
    "    def __init__(self, d_hid, d_inner_hid, dropout=0.1):\n",
    "        self.w_1 = Conv1D(d_inner_hid, 1, activation='relu')\n",
    "        self.w_2 = Conv1D(d_hid, 1)\n",
    "        self.layer_norm = LayerNormalization()\n",
    "        self.dropout = Dropout(dropout)\n",
    "    def __call__(self, x):\n",
    "        output = self.w_1(x) \n",
    "        output = self.w_2(output)\n",
    "        output = self.dropout(output)\n",
    "        output = Add()([output, x])\n",
    "        return self.layer_norm(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer():\n",
    "    def __init__(self, d_model, d_inner_hid, n_head, dropout=0.1):\n",
    "        self.self_att_layer = MultiHeadAttention(n_head, d_model, dropout=dropout)\n",
    "        self.pos_ffn_layer  = PositionwiseFeedForward(d_model, d_inner_hid, dropout=dropout)\n",
    "        self.norm_layer = LayerNormalization()\n",
    "    def __call__(self, enc_input, mask=None):\n",
    "        output, slf_attn = self.self_att_layer(enc_input, enc_input, enc_input, mask=mask)\n",
    "        output = self.norm_layer(Add()([enc_input, output]))\n",
    "        output = self.pos_ffn_layer(output)\n",
    "        return output, slf_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer():\n",
    "    def __init__(self, d_model, d_inner_hid, n_head, dropout=0.1):\n",
    "        self.self_att_layer = MultiHeadAttention(n_head, d_model, dropout=dropout)\n",
    "        self.enc_att_layer  = MultiHeadAttention(n_head, d_model, dropout=dropout)\n",
    "        self.pos_ffn_layer  = PositionwiseFeedForward(d_model, d_inner_hid, dropout=dropout)\n",
    "        self.norm_layer1 = LayerNormalization()\n",
    "        self.norm_layer2 = LayerNormalization()\n",
    "    def __call__(self, dec_input, enc_output, self_mask=None, enc_mask=None, dec_last_state=None):\n",
    "        if dec_last_state is None: dec_last_state = dec_input\n",
    "        output, slf_attn = self.self_att_layer(dec_input, dec_last_state, dec_last_state, mask=self_mask)\n",
    "        x = self.norm_layer1(Add()([dec_input, output]))\n",
    "        output, enc_attn = self.enc_att_layer(x, enc_output, enc_output, mask=enc_mask)\n",
    "        x = self.norm_layer2(Add()([x, output]))\n",
    "        output = self.pos_ffn_layer(x)\n",
    "        return output, slf_attn, enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPosEncodingMatrix(max_len, d_emb):\n",
    "    pos_enc = np.array([\n",
    "        [pos / np.power(10000, 2 * (j // 2) / d_emb) for j in range(d_emb)] \n",
    "        if pos != 0 else np.zeros(d_emb) \n",
    "            for pos in range(max_len)\n",
    "            ])\n",
    "    pos_enc[1:, 0::2] = np.sin(pos_enc[1:, 0::2]) # dim 2i\n",
    "    pos_enc[1:, 1::2] = np.cos(pos_enc[1:, 1::2]) # dim 2i+1\n",
    "    return pos_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPadMask(q, k):\n",
    "    '''\n",
    "    shape: [B, Q, K]\n",
    "    '''\n",
    "    ones = K.expand_dims(K.ones_like(q, 'float32'), -1)\n",
    "    mask = K.cast(K.expand_dims(K.not_equal(k, 0), 1), 'float32')\n",
    "    mask = K.batch_dot(ones, mask, axes=[2,1])\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSubMask(s):\n",
    "    '''\n",
    "    shape: [B, Q, K], lower triangle because the i-th row should have i 1s.\n",
    "    '''\n",
    "    len_s = tf.shape(s)[1]\n",
    "    bs = tf.shape(s)[:1]\n",
    "    mask = K.cumsum(tf.eye(len_s, batch_shape=bs), 1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention():\n",
    "    def __init__(self, d_model, d_inner_hid, n_head, layers=6, dropout=0.1):\n",
    "        self.layers = [EncoderLayer(d_model, d_inner_hid, n_head, dropout) for _ in range(layers)]\n",
    "    def __call__(self, src_emb, src_seq, return_att=False, active_layers=999):\n",
    "        if return_att: atts = []\n",
    "        mask = Lambda(lambda x:K.cast(K.greater(x, 0), 'float32'))(src_seq)\n",
    "        x = src_emb\t\t\n",
    "        for enc_layer in self.layers[:active_layers]:\n",
    "            x, att = enc_layer(x, mask)\n",
    "            if return_att: atts.append(att)\n",
    "        return (x, atts) if return_att else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder():\n",
    "    def __init__(self, d_model, d_inner_hid, n_head, layers=6, dropout=0.1):\n",
    "        self.layers = [DecoderLayer(d_model, d_inner_hid, n_head, dropout) for _ in range(layers)]\n",
    "    def __call__(self, tgt_emb, tgt_seq, src_seq, enc_output, return_att=False, active_layers=999):\n",
    "        x = tgt_emb\n",
    "        self_pad_mask = Lambda(lambda x:GetPadMask(x, x))(tgt_seq)\n",
    "        self_sub_mask = Lambda(GetSubMask)(tgt_seq)\n",
    "        self_mask = Lambda(lambda x:K.minimum(x[0], x[1]))([self_pad_mask, self_sub_mask])\n",
    "        enc_mask = Lambda(lambda x:GetPadMask(x[0], x[1]))([tgt_seq, src_seq])\n",
    "        if return_att: self_atts, enc_atts = [], []\n",
    "        for dec_layer in self.layers[:active_layers]:\n",
    "            x, self_att, enc_att = dec_layer(x, enc_output, self_mask, enc_mask)\n",
    "            if return_att: \n",
    "                self_atts.append(self_att)\n",
    "                enc_atts.append(enc_att)\n",
    "        return (x, self_atts, enc_atts) if return_att else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderPerStep(Layer):\n",
    "    def __init__(self, decoder):\n",
    "        super().__init__()\n",
    "        self.layers = decoder.layers\n",
    "    def call(self, inputs):\n",
    "        (x, src_seq, enc_output), tgt_embs = inputs[:3], inputs[3:]\n",
    "        enc_mask = K.cast(K.greater(src_seq, 0), 'float32')\n",
    "        llen = tf.shape(tgt_embs[0])[1]\n",
    "        col_mask = K.cast(K.equal(K.cumsum(K.ones_like(tgt_embs[0], dtype='int32'), axis=1), llen), dtype='float32')\n",
    "        rs = [x]\n",
    "        for i, dec_layer in enumerate(self.layers):\n",
    "            tgt_emb = tgt_embs[i] + x * col_mask\n",
    "            x, _, _ = dec_layer(x, enc_output, enc_mask=enc_mask, dec_last_state=tgt_emb)\n",
    "            rs.append(x)\n",
    "        return rs\n",
    "    def compute_output_shape(self, ishape):\n",
    "        return [ishape[0] for _ in range(len(self.layers)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderPerStep(Layer):\n",
    "    def __init__(self, decoder):\n",
    "        super().__init__()\n",
    "        self.layers = decoder.layers\n",
    "    def call(self, inputs):\n",
    "        (x, src_seq, enc_output), tgt_embs = inputs[:3], inputs[3:]\n",
    "        enc_mask = K.cast(K.greater(src_seq, 0), 'float32')\n",
    "        llen = tf.shape(tgt_embs[0])[1]\n",
    "        col_mask = K.cast(K.equal(K.cumsum(K.ones_like(tgt_embs[0], dtype='int32'), axis=1), llen), dtype='float32')\n",
    "        rs = [x]\n",
    "        for i, dec_layer in enumerate(self.layers):\n",
    "            tgt_emb = tgt_embs[i] + x * col_mask\n",
    "            x, _, _ = dec_layer(x, enc_output, enc_mask=enc_mask, dec_last_state=tgt_emb)\n",
    "            rs.append(x)\n",
    "        return rs\n",
    "    def compute_output_shape(self, ishape):\n",
    "        return [ishape[0] for _ in range(len(self.layers)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadoutDecoderCell(Layer):\n",
    "    def __init__(self, o_word_emb, pos_emb, decoder, target_layer, **kwargs):\n",
    "        self.o_word_emb = o_word_emb\n",
    "        self.pos_emb = pos_emb\n",
    "        self.decoder = decoder\n",
    "        self.target_layer = target_layer\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, inputs, states, constants, training=None):\n",
    "        (tgt_curr_input, tgt_pos_input, dec_mask), dec_output = states[:3], list(states[3:])\n",
    "        enc_output, enc_mask = constants\n",
    "\n",
    "        time = K.max(tgt_pos_input)\n",
    "        col_mask = K.cast(K.equal(K.cumsum(K.ones_like(dec_mask), axis=1), time), dtype='int32')\n",
    "        dec_mask = dec_mask + col_mask\n",
    "\n",
    "        tgt_emb = self.o_word_emb(tgt_curr_input)\n",
    "        if self.pos_emb: tgt_emb = tgt_emb + self.pos_emb(tgt_pos_input, pos_input=True)\n",
    "\n",
    "        x = tgt_emb\n",
    "        xs = []\n",
    "        cc = K.cast(K.expand_dims(col_mask), dtype='float32')\n",
    "        for i, dec_layer in enumerate(self.decoder.layers):\n",
    "            dec_last_state = dec_output[i] * (1-cc) + tf.einsum('ijk,ilj->ilk', x, cc)\n",
    "            x, _, _ = dec_layer(x, enc_output, dec_mask, enc_mask, dec_last_state=dec_last_state)\n",
    "            xs.append(dec_last_state)\n",
    "\n",
    "        ff_output = self.target_layer(x)\n",
    "        out = K.cast(K.argmax(ff_output, -1), dtype='int32')\n",
    "        return out, [out, tgt_pos_input+1, dec_mask] + xs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferRNN(Layer):\n",
    "    def __init__(self, cell, return_sequences=False, go_backwards=False, **kwargs):\n",
    "        if not hasattr(cell, 'call'):\n",
    "            raise ValueError('`cell` should have a `call` method. ' 'The RNN was passed:', cell)\n",
    "        super().__init__(**kwargs)\n",
    "        self.cell = cell\n",
    "        self.return_sequences = return_sequences\n",
    "        self.go_backwards = go_backwards\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1], 1) if self.return_sequences else (input_shape[0], 1)\n",
    "            \n",
    "    def __call__(self, inputs, initial_state=None, constants=None, **kwargs):\n",
    "        if initial_state is not None:\n",
    "            kwargs['initial_state'] = initial_state\n",
    "        if constants is not None:\n",
    "            kwargs['constants'] = constants\n",
    "            self._num_constants = len(constants)\n",
    "        return super().__call__(inputs, **kwargs)\n",
    "\n",
    "    def call(self, inputs, mask=None, training=None, initial_state=None, constants=None):\n",
    "        if isinstance(inputs, list):\n",
    "            if self._num_constants is None: initial_state = inputs[1:]\n",
    "            else: initial_state = inputs[1:-self._num_constants]\n",
    "            inputs = inputs[0]\n",
    "        input_shape = K.int_shape(inputs)\n",
    "        timesteps = input_shape[1]\n",
    "\n",
    "        kwargs = {}\n",
    "        def step(inputs, states):\n",
    "            constants = states[-self._num_constants:]\n",
    "            states = states[:-self._num_constants]\n",
    "            return self.cell.call(inputs, states, constants=constants, **kwargs)\n",
    "\n",
    "        last_output, outputs, states = K.rnn(step, inputs, initial_state, constants=constants,\n",
    "                                                go_backwards=self.go_backwards,\n",
    "                                                mask=mask, unroll=False, input_length=timesteps)\n",
    "        output = outputs if self.return_sequences else last_output\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_batch_greedy(src_seq, encode_model, decode_model, start_mark, end_mark, max_len=128):\n",
    "    enc_ret = encode_model.predict_on_batch(src_seq)\n",
    "    bs = src_seq.shape[0]\n",
    "    target_one = np.zeros((bs, 1), dtype='int32')\n",
    "    target_one[:,0] = start_mark\n",
    "    d_model = decode_model.inputs[-1].shape[-1]\n",
    "    n_dlayers = len(decode_model.inputs) - 3\n",
    "    dec_outputs = [np.zeros((bs, 1, d_model)) for _ in range(n_dlayers)]\n",
    "    ended = [0 for x in range(bs)]\n",
    "    decoded_indexes = [[] for x in range(bs)]\n",
    "    for i in range(max_len-1):\n",
    "        outputs = decode_model.predict_on_batch([target_one, src_seq, enc_ret] + dec_outputs)\n",
    "        new_dec_outputs, output = outputs[:-1], outputs[-1]\n",
    "        for dec_output, new_out in zip(dec_outputs, new_dec_outputs): \n",
    "            dec_output[:,-1,:] = new_out[:,0,:]\n",
    "        dec_outputs = [np.concatenate([x, np.zeros_like(new_out)], axis=1) for x in dec_outputs]\n",
    "\n",
    "        sampled_indexes = np.argmax(output[:,0,:], axis=-1)\n",
    "        for ii, sampled_index in enumerate(sampled_indexes):\n",
    "            if sampled_index == end_mark: ended[ii] = 1\n",
    "            if not ended[ii]: decoded_indexes[ii].append(sampled_index)\n",
    "        if sum(ended) == bs: break\n",
    "        target_one[:,0] = sampled_indexes\n",
    "    return decoded_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_batch_beam_search(src_seq, topk, encode_model, decode_model, start_mark, end_mark, max_len=128, early_stop_mult=5):\n",
    "    N = src_seq.shape[0]\n",
    "    src_seq = src_seq.repeat(topk, 0)\n",
    "    enc_ret = encode_model.predict_on_batch(src_seq)\n",
    "    bs = src_seq.shape[0]\n",
    "\n",
    "    target_one = np.zeros((bs, 1), dtype='int32')\n",
    "    target_one[:,0] = start_mark\n",
    "    d_model = decode_model.inputs[-1].shape[-1]\n",
    "    n_dlayers = len(decode_model.inputs) - 3\n",
    "    dec_outputs = [np.zeros((bs, 1, d_model)) for _ in range(n_dlayers)]\n",
    "\n",
    "    final_results = []\n",
    "    decoded_indexes = [[] for x in range(bs)]\n",
    "    decoded_logps = [0] * bs\n",
    "    lastks = [1 for x in range(N)]\n",
    "    bests = {}\n",
    "    for i in range(max_len-1):\n",
    "        outputs = decode_model.predict_on_batch([target_one, src_seq, enc_ret] + dec_outputs)\n",
    "        new_dec_outputs, output = outputs[:-1], outputs[-1]\n",
    "        for dec_output, new_out in zip(dec_outputs, new_dec_outputs): \n",
    "            dec_output[:,-1,:] = new_out[:,0,:]\n",
    "\n",
    "        dec_outputs = [np.concatenate([x, np.zeros_like(new_out)], axis=1) for x in dec_outputs]\n",
    "\n",
    "        output = np.exp(output[:,0,:])\n",
    "        output = np.log(output / np.sum(output, -1, keepdims=True) + 1e-8)\n",
    "\n",
    "        next_dec_outputs = [x.copy() for x in dec_outputs]\n",
    "        next_decoded_indexes = [1 for x in range(bs)]\n",
    "\n",
    "        for ii in range(N):\n",
    "            base = ii * topk\n",
    "            cands = []\n",
    "            for k, wprobs in zip(range(lastks[ii]), output[base:,:]):\n",
    "                prev = base+k\n",
    "                if len(decoded_indexes[prev]) > 0 and decoded_indexes[prev][-1] == end_mark: continue\n",
    "                ind = np.argpartition(wprobs, -topk)[-topk:]\n",
    "                wsorted = [(k,x) for k,x in zip(ind, wprobs[ind])]\n",
    "                #wsorted = sorted(list(enumerate(wprobs)), key=lambda x:x[-1], reverse=True)   # slow\n",
    "                for wid, wp in wsorted[:topk]: \n",
    "                    wprob = decoded_logps[prev]+wp\n",
    "                    if wprob < bests.get(ii, -1e5) * early_stop_mult: continue\n",
    "                    cands.append( (prev, wid, wprob) )\n",
    "            cands.sort(key=lambda x:x[-1], reverse=True)\t\n",
    "            cands = cands[:topk]\n",
    "            lastks[ii] = len(cands)\n",
    "            for kk, zz in enumerate(cands):\n",
    "                prev, wid, wprob = zz\n",
    "                npos = base+kk\n",
    "                for k in range(len(next_dec_outputs)):\n",
    "                    next_dec_outputs[k][npos,:,:] = dec_outputs[k][prev]\n",
    "                target_one[npos,0] = wid\n",
    "                decoded_logps[npos] = wprob\n",
    "                next_decoded_indexes[npos] = decoded_indexes[prev].copy()\n",
    "                next_decoded_indexes[npos].append(wid)\n",
    "                if wid == end_mark:\n",
    "                    final_results.append( (ii, decoded_indexes[prev].copy(), wprob) ) \n",
    "                    if ii not in bests or wprob > bests[ii]: bests[ii] = wprob\n",
    "        if sum(lastks) == 0: break\n",
    "        dec_outputs = next_dec_outputs\n",
    "        decoded_indexes = next_decoded_indexes\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer:\n",
    "    def __init__(self, i_tokens, o_tokens, len_limit, d_model=256, \\\n",
    "                d_inner_hid=512, n_head=4, layers=2, dropout=0.1, \\\n",
    "                share_word_emb=False):\n",
    "        self.i_tokens = i_tokens\n",
    "        self.o_tokens = o_tokens\n",
    "        self.len_limit = len_limit\n",
    "        self.d_model = d_model\n",
    "        self.decode_model = None\n",
    "        self.readout_model = None\n",
    "        self.layers = layers\n",
    "        d_emb = d_model\n",
    "\n",
    "        self.src_loc_info = True\n",
    "\n",
    "        d_k = d_v = d_model // n_head\n",
    "        assert d_k * n_head == d_model and d_v == d_k\n",
    "\n",
    "        self.pos_emb = PosEncodingLayer(len_limit, d_emb) if self.src_loc_info else None\n",
    "\n",
    "        self.emb_dropout = Dropout(dropout)\n",
    "\n",
    "        self.i_word_emb = Embedding(i_tokens.num(), d_emb)\n",
    "        if share_word_emb: \n",
    "            assert i_tokens.num() == o_tokens.num()\n",
    "            self.o_word_emb = i_word_emb\n",
    "        else: self.o_word_emb = Embedding(o_tokens.num(), d_emb)\n",
    "\n",
    "        self.encoder = SelfAttention(d_model, d_inner_hid, n_head, layers, dropout)\n",
    "        self.decoder = Decoder(d_model, d_inner_hid, n_head, layers, dropout)\n",
    "        self.target_layer = TimeDistributed(Dense(o_tokens.num(), use_bias=False))\n",
    "\n",
    "    def compile(self, optimizer='adam', active_layers=999):\n",
    "        src_seq_input = Input(shape=(None,), dtype='int32')\n",
    "        tgt_seq_input = Input(shape=(None,), dtype='int32')\n",
    "\n",
    "        src_seq = src_seq_input\n",
    "        tgt_seq  = Lambda(lambda x:x[:,:-1])(tgt_seq_input)\n",
    "        tgt_true = Lambda(lambda x:x[:,1:])(tgt_seq_input)\n",
    "\n",
    "        src_emb = self.i_word_emb(src_seq)\n",
    "        tgt_emb = self.o_word_emb(tgt_seq)\n",
    "\n",
    "        if self.pos_emb: \n",
    "            src_emb = add_layer([src_emb, self.pos_emb(src_seq)])\n",
    "            tgt_emb = add_layer([tgt_emb, self.pos_emb(tgt_seq)])\n",
    "        src_emb = self.emb_dropout(src_emb)\n",
    "\n",
    "        enc_output = self.encoder(src_emb, src_seq, active_layers=active_layers)\n",
    "        dec_output = self.decoder(tgt_emb, tgt_seq, src_seq, enc_output, active_layers=active_layers)\t\n",
    "        final_output = self.target_layer(dec_output)\n",
    "\n",
    "        def get_loss(y_pred, y_true):\n",
    "            y_true = tf.cast(y_true, 'int32')\n",
    "            loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "            mask = tf.cast(tf.not_equal(y_true, 0), 'float32')\n",
    "            loss = tf.reduce_sum(loss * mask, -1) / tf.reduce_sum(mask, -1)\n",
    "            loss = K.mean(loss)\n",
    "            return loss\n",
    "\n",
    "        def get_accu(y_pred, y_true):\n",
    "            mask = tf.cast(tf.not_equal(y_true, 0), 'float32')\n",
    "            corr = K.cast(K.equal(K.cast(y_true, 'int32'), K.cast(K.argmax(y_pred, axis=-1), 'int32')), 'float32')\n",
    "            corr = K.sum(corr * mask, -1) / K.sum(mask, -1)\n",
    "            return K.mean(corr)\n",
    "\n",
    "        loss = get_loss(final_output, tgt_true)\n",
    "        self.ppl = K.exp(loss)\n",
    "        self.accu = get_accu(final_output, tgt_true)\n",
    "\n",
    "        self.model = Model([src_seq_input, tgt_seq_input], final_output)\n",
    "        self.model.add_loss([loss])\n",
    "\n",
    "        self.model.compile(optimizer, None)\n",
    "        self.model.metrics_names.append('ppl')\n",
    "        self.model.metrics_tensors.append(self.ppl)\n",
    "        self.model.metrics_names.append('accu')\n",
    "        self.model.metrics_tensors.append(self.accu)\n",
    "\n",
    "    def make_src_seq_matrix(self, input_seqs):\n",
    "        if type(input_seqs[0]) == type(''): input_seqs = [input_seqs]\n",
    "        maxlen = max(map(len, input_seqs))\n",
    "        src_seq = np.zeros((len(input_seqs), maxlen+3), dtype='int32')\n",
    "        src_seq[:,0] = self.i_tokens.startid()\n",
    "        for i, seq in enumerate(input_seqs):\n",
    "            for ii, z in enumerate(seq):\n",
    "                src_seq[i,1+ii] = self.i_tokens.id(z)\n",
    "            src_seq[i,1+len(seq)] = self.i_tokens.endid()\n",
    "        return src_seq\n",
    "\n",
    "    def make_readout_decode_model(self, max_output_len=32):\n",
    "        src_seq_input = Input(shape=(None,), dtype='int32')\n",
    "        tgt_start_input = Input(shape=(1,), dtype='int32')\n",
    "        src_seq = src_seq_input\n",
    "        enc_mask = Lambda(lambda x:K.cast(K.greater(x, 0), 'float32'))(src_seq)\n",
    "        src_emb = self.i_word_emb(src_seq)\n",
    "        if self.pos_emb: \n",
    "            src_emb = add_layer([src_emb, self.pos_emb(src_seq)])\n",
    "\n",
    "        src_emb = self.emb_dropout(src_emb)\n",
    "        enc_output = self.encoder(src_emb, src_seq)\n",
    "\n",
    "        tgt_emb = self.o_word_emb(tgt_start_input)\n",
    "        tgt_seq = Lambda(lambda x:K.repeat_elements(x, max_output_len, 1))(tgt_start_input)\n",
    "        rep_input = Lambda(lambda x:K.repeat_elements(x, max_output_len, 1))(tgt_emb)\n",
    "\n",
    "        cell = ReadoutDecoderCell(self.o_word_emb, self.pos_emb, self.decoder, self.target_layer)\n",
    "        final_output = InferRNN(cell, return_sequences=True)(rep_input, \n",
    "                initial_state=[tgt_start_input, K.ones_like(tgt_start_input), K.zeros_like(tgt_seq)] + \\\n",
    "                        [rep_input for _ in self.decoder.layers], \n",
    "                constants=[enc_output, enc_mask])\n",
    "        final_output = Lambda(lambda x:K.squeeze(x, -1))(final_output)\n",
    "        self.readout_model = Model([src_seq_input, tgt_start_input], final_output)\n",
    "    \n",
    "    def decode_sequence_readout_x(self, X, batch_size=32, max_output_len=64):\n",
    "        if self.readout_model is None: self.make_readout_decode_model(max_output_len)\n",
    "        target_seq = np.zeros((X.shape[0], 1), dtype='int32')\n",
    "        target_seq[:,0] = self.o_tokens.startid()\n",
    "        ret = self.readout_model.predict([X, target_seq], batch_size=batch_size, verbose=1)\n",
    "        return ret\n",
    "\n",
    "    def generate_sentence(self, rets, delimiter=''):\n",
    "        sents = []\n",
    "        for x in rets:\n",
    "            end_pos = min([i for i, z in enumerate(x) if z == self.o_tokens.endid()]+[len(x)])\n",
    "            rsent = [*map(self.o_tokens.token, x)][:end_pos]\n",
    "            sents.append(delimiter.join(rsent))\n",
    "        return sents\n",
    "\n",
    "    def decode_sequence_readout(self, input_seqs, delimiter=''):\n",
    "        if self.readout_model is None: self.make_readout_decode_model()\n",
    "        src_seq = self.make_src_seq_matrix(input_seqs)\n",
    "        target_seq = np.zeros((src_seq.shape[0],1), dtype='int32')\n",
    "        target_seq[:,0] = self.o_tokens.startid()\n",
    "        rets = self.readout_model.predict([src_seq, target_seq])\n",
    "        rets = self.generate_sentence(rets, delimiter)\n",
    "        if type(input_seqs[0]) is type('') and len(rets) == 1: rets = rets[0]\n",
    "        return rets\n",
    "\n",
    "    def make_fast_decode_model(self):\n",
    "        src_seq_input = Input(shape=(None,), dtype='int32')\n",
    "        src_emb = self.i_word_emb(src_seq_input)\n",
    "        if self.pos_emb: src_emb = add_layer([src_emb, self.pos_emb(src_seq_input)])\n",
    "        src_emb = self.emb_dropout(src_emb)\n",
    "        enc_output = self.encoder(src_emb, src_seq_input)\n",
    "        self.encode_model = Model(src_seq_input, enc_output)\n",
    "\n",
    "        self.decoder_pre_step = DecoderPerStep(self.decoder)\n",
    "\n",
    "        src_seq_input = Input(shape=(None,), dtype='int32')\n",
    "        tgt_one_input = Input(shape=(1,), dtype='int32')\n",
    "        enc_ret_input = Input(shape=(None, self.d_model))\n",
    "        dec_ret_inputs = [Input(shape=(None, self.d_model)) for _ in self.decoder.layers]\n",
    "\n",
    "        tgt_pos = Lambda(lambda x:tf.shape(x)[1])(dec_ret_inputs[0])\n",
    "\n",
    "        tgt_one = self.o_word_emb(tgt_one_input)\n",
    "        if self.pos_emb: tgt_one = add_layer([tgt_one, self.pos_emb(tgt_pos, pos_input=True)])\n",
    "\n",
    "        dec_outputs = self.decoder_pre_step([tgt_one, src_seq_input, enc_ret_input]+dec_ret_inputs)\t\n",
    "        final_output = self.target_layer(dec_outputs[-1])\n",
    "\n",
    "        self.decode_model = Model([tgt_one_input, src_seq_input, enc_ret_input]+dec_ret_inputs, \n",
    "                            dec_outputs[:-1]+[final_output])\n",
    "\n",
    "    def decode_sequence_fast(self, input_seqs, batch_size=32, delimiter='', verbose=0):\n",
    "        if self.decode_model is None: self.make_fast_decode_model()\n",
    "        src_seq = self.make_src_seq_matrix(input_seqs)\n",
    "\n",
    "        start_mark, end_mark = self.o_tokens.startid(), self.o_tokens.endid()\n",
    "        max_len = self.len_limit\n",
    "        encode_model = self.encode_model\n",
    "        decode_model = self.decode_model\n",
    "\n",
    "        decode_batch = lambda x: decode_batch_greedy(x, encode_model, decode_model, start_mark, end_mark, max_len)\n",
    "\n",
    "        rets = []\n",
    "        rng = range(0, src_seq.shape[0], batch_size)\n",
    "        if verbose and src_seq.shape[0] > batch_size: rng = tqdm(rng, total=len(rng))\n",
    "        for iter in rng:\n",
    "            rets.extend( decode_batch(src_seq[iter:iter+batch_size]) )\n",
    "            \n",
    "        rets = [delimiter.join(list(map(self.o_tokens.token, ret))) for ret in rets]\n",
    "        if type(input_seqs[0]) is type('') and len(rets) == 1: rets = rets[0]\n",
    "        return rets\n",
    "\n",
    "    def beam_search(self, input_seqs, topk=5, batch_size=8, length_penalty=1, delimiter='', verbose=0):\n",
    "        if self.decode_model is None: self.make_fast_decode_model()\n",
    "        src_seq = self.make_src_seq_matrix(input_seqs)\n",
    "\n",
    "        start_mark, end_mark = self.o_tokens.startid(), self.o_tokens.endid()\n",
    "        max_len = self.len_limit\n",
    "        encode_model = self.encode_model\n",
    "        decode_model = self.decode_model\n",
    "\n",
    "        decode_batch = lambda x: decode_batch_beam_search(x, topk, encode_model, decode_model,\n",
    "                                                    start_mark, end_mark, max_len)\n",
    "        \n",
    "        rets = {}\n",
    "        rng = range(0, src_seq.shape[0], batch_size)\n",
    "        if verbose and src_seq.shape[0] > batch_size: rng = tqdm(rng, total=len(rng))\n",
    "\n",
    "        for iter in rng:\n",
    "            for i, x, y in decode_batch(src_seq[iter:iter+batch_size]):\n",
    "                rets.setdefault(iter+i, []).append( (x, y/np.power(len(x)+1, length_penalty)) )\n",
    "        rets = {x:sorted(ys,key=lambda x:x[-1], reverse=True) for x,ys in rets.items()}\n",
    "        rets = [rets[i] for i in range(len(rets))]\n",
    "\n",
    "        rets = [[(delimiter.join(list(map(self.o_tokens.token, x))), y) for x, y in r] for r in rets]\n",
    "        if type(input_seqs[0]) is type('') and len(rets) == 1: rets = rets[0]\n",
    "        return rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PosEncodingLayer:\n",
    "    def __init__(self, max_len, d_emb):\n",
    "        self.pos_emb_matrix = Embedding(max_len, d_emb, trainable=False, \\\n",
    "                           weights=[GetPosEncodingMatrix(max_len, d_emb)])\n",
    "    def get_pos_seq(self, x):\n",
    "        mask = K.cast(K.not_equal(x, 0), 'int32')\n",
    "        pos = K.cumsum(K.ones_like(x, 'int32'), 1)\n",
    "        return pos * mask\n",
    "    def __call__(self, seq, pos_input=False):\n",
    "        x = seq\n",
    "        if not pos_input: x = Lambda(self.get_pos_seq)(x)\n",
    "        return self.pos_emb_matrix(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddPosEncoding:\n",
    "    def __call__(self, x):\n",
    "        _, max_len, d_emb = K.int_shape(x)\n",
    "        pos = GetPosEncodingMatrix(max_len, d_emb)\n",
    "        x = Lambda(lambda x:x+pos)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRSchedulerPerStep(Callback):\n",
    "    def __init__(self, d_model, warmup=4000):\n",
    "        self.basic = d_model**-0.5\n",
    "        self.warm = warmup**-1.5\n",
    "        self.step_num = 0\n",
    "    def on_batch_begin(self, batch, logs = None):\n",
    "        self.step_num += 1\n",
    "        lr = self.basic * min(self.step_num**-0.5, self.step_num*self.warm)\n",
    "        K.set_value(self.model.optimizer.lr, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_layer = Lambda(lambda x:x[0]+x[1], output_shape=lambda x:x[0])\n",
    "# use this because keras may get wrong shapes with Add()([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QANet_ConvBlock:\n",
    "    def __init__(self, dim, n_conv=2, kernel_size=7, dropout=0.1):\n",
    "        self.convs = [SeparableConv1D(dim, kernel_size, activation='relu', padding='same') for _ in range(n_conv)]\n",
    "        self.norm = LayerNormalization()\n",
    "        self.dropout = Dropout(dropout)\n",
    "    def __call__(self, x):\n",
    "        for i in range(len(self.convs)):\n",
    "            z = self.norm(x)\n",
    "            if i % 2 == 0: z = self.dropout(z)\n",
    "            z = self.convs[i](z)\n",
    "            x = add_layer([x, z])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QANet_Block:\n",
    "    def __init__(self, dim, n_head, n_conv, kernel_size, dropout=0.1, add_pos=True):\n",
    "        self.conv = QANet_ConvBlock(dim, n_conv=n_conv, kernel_size=kernel_size, dropout=dropout)\n",
    "        self.self_att = MultiHeadAttention(n_head=n_head, d_model=dim, \n",
    "                                            d_k=dim//n_head, d_v=dim//n_head, \n",
    "                                            dropout=dropout, use_norm=False)\n",
    "        self.feed_forward = PositionwiseFeedForward(dim, dim, dropout=dropout)\n",
    "        self.norm = LayerNormalization()\n",
    "        self.add_pos = add_pos\n",
    "    def __call__(self, x, mask):\n",
    "        if self.add_pos: x = AddPosEncoding()(x)\n",
    "        x = self.conv(x)\n",
    "        z = self.norm(x)\n",
    "        z, _ = self.self_att(z, z, z, mask)\n",
    "        x = add_layer([x, z])\n",
    "        z = self.norm(x)\n",
    "        z = self.feed_forward(z)\n",
    "        x = add_layer([x, z])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QANet_Encoder:\n",
    "    def __init__(self, dim=128, n_head=8, n_conv=2, n_block=1, kernel_size=7, dropout=0.1, add_pos=True):\n",
    "        self.dim = dim\n",
    "        self.n_block = n_block\n",
    "        self.conv_first = SeparableConv1D(dim, 1, padding='same')\n",
    "        self.enc_block = QANet_Block(dim, n_head=n_head, n_conv=n_conv, kernel_size=kernel_size, \n",
    "                                    dropout=dropout, add_pos=add_pos)\n",
    "    def __call__(self, x, mask):\n",
    "        if K.int_shape(x)[-1] != self.dim:\n",
    "            x = self.conv_first(x)\n",
    "        for i in range(self.n_block):\n",
    "            x = self.enc_block(x, mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../Data/Preprocessed/reply.txt', 'r') as reply_file:\n",
    "#     reply_whole = reply_file.read()\n",
    "# with open('../Data/Preprocessed/title.txt', 'r') as title_file:\n",
    "#     title_whole = title_file.read()\n",
    "    \n",
    "# # 전체 텍스트의 마지막 빈 문장 제거 및 텍스트 리스트로 값 저장\n",
    "# replies_bundle = reply_whole.rstrip().split('\\n')\n",
    "# titles = title_whole.rstrip().split('\\n')\n",
    "\n",
    "# # 파일에서 불러온 텍스트의 개수 확인\n",
    "# assert(len(titles) == len(replies_bundle))\n",
    "\n",
    "# index_for_delete = []\n",
    "# for i in range(len(titles)):\n",
    "#     if titles[i] == '':\n",
    "#         index_for_delete.append(i)\n",
    "\n",
    "# for index in index_for_delete:\n",
    "#     del titles[index]\n",
    "#     del replies_bundle[index]\n",
    "# assert(len(titles) == len(replies_bundle))\n",
    "\n",
    "# # 베댓(첫번째 댓글)만 따로 리스트로 만들기\n",
    "# for i in range(len(replies_bundle)):\n",
    "#     replies_bundle[i] = eval(replies_bundle[i])\n",
    "# replies = [reply_bundle[0]['text'] for reply_bundle in replies_bundle]\n",
    "# assert(len(titles) == len(replies))\n",
    "\n",
    "# # 총 데이터의 갯수\n",
    "# num_data = len(titles)\n",
    "# print(num_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 데이터 이렇게 사용하면돼!\n",
    "mode = 'all' # all or best\n",
    "assert(mode in ['all', 'best'])\n",
    "\n",
    "with open('../Data/Preprocessed/titles-'+mode+'.txt', 'r') as reply_file:\n",
    "    titles = eval(reply_file.read())\n",
    "with open('../Data/Preprocessed/replies-'+mode+'.txt', 'r') as title_file:\n",
    "    replies = eval(title_file.read())\n",
    "# 유효성 검사\n",
    "\n",
    "assert(len(replies) == len(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from konlpy.tag import Okt\n",
    "# okt = Okt()\n",
    "\n",
    "# titles_m = []\n",
    "# for title in titles:\n",
    "#     title_m = ' '.join(okt.morphs(title, norm=False))\n",
    "#     titles_m.append(title_m)\n",
    "    \n",
    "# replies_m = []\n",
    "# for reply in replies:\n",
    "#     reply_m = ' '.join(okt.morphs(reply, norm=True))\n",
    "#     replies_m.append(reply_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titles = titles_m\n",
    "# replies = replies_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_whole, _, y_whole, _ = train_test_split(titles, replies, test_size=0.8)\n",
    "x_train, _x_test, y_train, _y_test = train_test_split(x_whole, y_whole, test_size=0.5)\n",
    "_x_train, x_test, _y_train, y_test = train_test_split(_x_test, _y_test, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data length:  10504\n",
      "test data length:  3152\n"
     ]
    }
   ],
   "source": [
    "print(\"train data length: \", len(x_train))\n",
    "print(\"test data length: \", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ti2re_whole.txt', 'w') as f:\n",
    "    for t, r in zip(x_whole, y_whole):\n",
    "        f.write(t+'\\t'+r+'\\n')\n",
    "\n",
    "with open('ti2re.txt', 'w') as f:\n",
    "    for t, r in zip(x_train, y_train):\n",
    "        f.write(t+'\\t'+r+'\\n')\n",
    "\n",
    "with open('ti2re_valid.txt', 'w') as f:\n",
    "    for t, r in zip(x_test, y_test):\n",
    "        f.write(t+'\\t'+r+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataloader as dd\n",
    "from keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq 1 words: 28119\n",
      "seq 2 words: 148444\n",
      "seq 1 words: 28123\n",
      "seq 2 words: 148448\n",
      "train shapes: (10504, 16) (10504, 85)\n",
      "valid shapes: (3152, 16) (3152, 81)\n"
     ]
    }
   ],
   "source": [
    "itokens, otokens = dd.MakeS2SDict('ti2re_whole.txt', dict_file='ti2re_word.txt', min_freq=1)\n",
    "Xtrain, Ytrain = dd.MakeS2SData('ti2re.txt', itokens, otokens, h5_file='ti2re.h5')\n",
    "Xvalid, Yvalid = dd.MakeS2SData('ti2re_valid.txt', itokens, otokens, h5_file='ti2re_valid.h5')\n",
    "\n",
    "print('seq 1 words:', itokens.num())\n",
    "print('seq 2 words:', otokens.num())\n",
    "print('train shapes:', Xtrain.shape, Ytrain.shape)\n",
    "print('valid shapes:', Xvalid.shape, Yvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 256\n",
    "s2s = Transformer(itokens, otokens, len_limit=70, d_model=d_model, d_inner_hid=512, \\\n",
    "                    n_head=8, layers=2, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfile = 'ti2re_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = LRSchedulerPerStep(d_model, 4000) \n",
    "model_saver = ModelCheckpoint(mfile, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "new model\n"
     ]
    }
   ],
   "source": [
    "s2s.compile(Adam(0.001, 0.9, 0.98, epsilon=1e-9))\n",
    "try: s2s.model.load_weights(mfile)\n",
    "except: print('\\n\\nnew model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10504 samples, validate on 3152 samples\n",
      "Epoch 1/30\n",
      "10504/10504 [==============================] - 140s 13ms/step - loss: 11.7491 - ppl: 127635.1605 - accu: 0.0727 - val_loss: 11.4924 - val_ppl: 98011.8273 - val_accu: 0.0963\n",
      "Epoch 2/30\n",
      "10504/10504 [==============================] - 135s 13ms/step - loss: 10.8317 - ppl: 52490.7805 - accu: 0.0966 - val_loss: 10.9271 - val_ppl: 55935.1409 - val_accu: 0.0963\n",
      "Epoch 3/30\n",
      "10504/10504 [==============================] - 140s 13ms/step - loss: 9.8045 - ppl: 18424.0509 - accu: 0.0966 - val_loss: 10.8023 - val_ppl: 49876.0083 - val_accu: 0.0963\n",
      "Epoch 4/30\n",
      "10504/10504 [==============================] - 144s 14ms/step - loss: 9.4971 - ppl: 13499.5322 - accu: 0.0966 - val_loss: 11.0930 - val_ppl: 66879.3802 - val_accu: 0.0963\n",
      "Epoch 5/30\n",
      "10504/10504 [==============================] - 146s 14ms/step - loss: 9.3222 - ppl: 11289.1359 - accu: 0.0966 - val_loss: 11.3655 - val_ppl: 88339.5785 - val_accu: 0.0949\n",
      "Epoch 6/30\n",
      "10504/10504 [==============================] - 146s 14ms/step - loss: 9.0338 - ppl: 8477.1076 - accu: 0.0978 - val_loss: 11.8859 - val_ppl: 150098.5219 - val_accu: 0.0964\n",
      "Epoch 7/30\n",
      "10504/10504 [==============================] - 147s 14ms/step - loss: 8.7745 - ppl: 6552.5711 - accu: 0.0983 - val_loss: 11.9021 - val_ppl: 152590.1169 - val_accu: 0.0930\n",
      "Epoch 8/30\n",
      "10504/10504 [==============================] - 143s 14ms/step - loss: 8.5339 - ppl: 5139.3154 - accu: 0.0999 - val_loss: 12.4977 - val_ppl: 280204.4946 - val_accu: 0.0942\n",
      "Epoch 9/30\n",
      "10504/10504 [==============================] - 132s 13ms/step - loss: 8.3282 - ppl: 4194.5246 - accu: 0.1014 - val_loss: 12.9671 - val_ppl: 454380.3683 - val_accu: 0.0921\n",
      "Epoch 10/30\n",
      "10504/10504 [==============================] - 132s 13ms/step - loss: 8.1608 - ppl: 3565.2921 - accu: 0.1036 - val_loss: 12.8531 - val_ppl: 400345.1621 - val_accu: 0.0869\n",
      "Epoch 11/30\n",
      "10504/10504 [==============================] - 132s 13ms/step - loss: 8.0090 - ppl: 3053.4007 - accu: 0.1098 - val_loss: 13.0408 - val_ppl: 487329.6152 - val_accu: 0.0904\n",
      "Epoch 12/30\n",
      "10504/10504 [==============================] - 132s 13ms/step - loss: 7.8553 - ppl: 2629.1262 - accu: 0.1164 - val_loss: 13.5555 - val_ppl: 819409.4987 - val_accu: 0.0892\n",
      "Epoch 13/30\n",
      "10504/10504 [==============================] - 132s 13ms/step - loss: 7.6848 - ppl: 2223.8186 - accu: 0.1221 - val_loss: 13.0604 - val_ppl: 495598.8745 - val_accu: 0.0893\n",
      "Epoch 14/30\n",
      "10504/10504 [==============================] - 132s 13ms/step - loss: 7.4867 - ppl: 1821.5547 - accu: 0.1274 - val_loss: 12.9790 - val_ppl: 457305.3572 - val_accu: 0.0908\n",
      "Epoch 15/30\n",
      "10504/10504 [==============================] - 132s 13ms/step - loss: 7.2605 - ppl: 1456.5537 - accu: 0.1338 - val_loss: 13.5021 - val_ppl: 776896.3531 - val_accu: 0.0846\n",
      "Epoch 16/30\n",
      "10504/10504 [==============================] - 132s 13ms/step - loss: 6.9856 - ppl: 1106.0223 - accu: 0.1416 - val_loss: 13.4708 - val_ppl: 757862.7754 - val_accu: 0.0892\n",
      "Epoch 17/30\n",
      "10504/10504 [==============================] - 132s 13ms/step - loss: 6.6576 - ppl: 796.1704 - accu: 0.1508 - val_loss: 14.1468 - val_ppl: 1517939.6612 - val_accu: 0.0881\n",
      "Epoch 18/30\n",
      "10504/10504 [==============================] - 132s 13ms/step - loss: 6.2460 - ppl: 529.1721 - accu: 0.1685 - val_loss: 13.5648 - val_ppl: 831203.1726 - val_accu: 0.0797\n",
      "Epoch 19/30\n",
      "10504/10504 [==============================] - 132s 13ms/step - loss: 5.7426 - ppl: 320.2283 - accu: 0.2045 - val_loss: 13.5591 - val_ppl: 828407.6434 - val_accu: 0.0819\n",
      "Epoch 20/30\n",
      "10504/10504 [==============================] - 132s 13ms/step - loss: 5.1391 - ppl: 175.4410 - accu: 0.2820 - val_loss: 14.2541 - val_ppl: 1675788.8128 - val_accu: 0.0830\n",
      "Epoch 21/30\n",
      "10504/10504 [==============================] - 132s 13ms/step - loss: 4.4611 - ppl: 89.3563 - accu: 0.4066 - val_loss: 13.9965 - val_ppl: 1298493.8864 - val_accu: 0.0868\n",
      "Epoch 22/30\n",
      "10504/10504 [==============================] - 132s 13ms/step - loss: 3.7251 - ppl: 42.5412 - accu: 0.5384 - val_loss: 14.9172 - val_ppl: 3328189.5114 - val_accu: 0.0906\n",
      "Epoch 23/30\n",
      "10504/10504 [==============================] - 132s 13ms/step - loss: 2.9787 - ppl: 20.2992 - accu: 0.6446 - val_loss: 14.5744 - val_ppl: 2324800.0013 - val_accu: 0.0931\n",
      "Epoch 24/30\n",
      "10504/10504 [==============================] - 132s 13ms/step - loss: 2.3202 - ppl: 10.4537 - accu: 0.7149 - val_loss: 13.8610 - val_ppl: 1122840.8109 - val_accu: 0.0939\n",
      "Epoch 25/30\n",
      "10504/10504 [==============================] - 132s 13ms/step - loss: 1.8456 - ppl: 6.4316 - accu: 0.7613 - val_loss: 15.3876 - val_ppl: 5297877.3604 - val_accu: 0.0929\n",
      "Epoch 26/30\n",
      "10504/10504 [==============================] - 132s 13ms/step - loss: 1.5379 - ppl: 4.7014 - accu: 0.7912 - val_loss: 15.2146 - val_ppl: 4453763.6091 - val_accu: 0.0908\n",
      "Epoch 27/30\n",
      "10504/10504 [==============================] - 132s 13ms/step - loss: 1.3614 - ppl: 3.9369 - accu: 0.8105 - val_loss: 14.7443 - val_ppl: 2742775.2665 - val_accu: 0.0906\n",
      "Epoch 28/30\n",
      "10504/10504 [==============================] - 132s 13ms/step - loss: 1.2583 - ppl: 3.5489 - accu: 0.8226 - val_loss: 14.9937 - val_ppl: 3548676.4429 - val_accu: 0.0919\n",
      "Epoch 29/30\n",
      "10504/10504 [==============================] - 132s 13ms/step - loss: 1.1862 - ppl: 3.2997 - accu: 0.8329 - val_loss: 15.4143 - val_ppl: 5371658.5228 - val_accu: 0.0950\n",
      "Epoch 30/30\n",
      "10504/10504 [==============================] - 132s 13ms/step - loss: 1.1328 - ppl: 3.1266 - accu: 0.8396 - val_loss: 14.9210 - val_ppl: 3297662.1954 - val_accu: 0.0969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6b718f6748>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#s2s.model.summary()\n",
    "s2s.model.fit([Xtrain, Ytrain], None, batch_size=64, epochs=30, \\\n",
    "                validation_data=([Xvalid, Yvalid], None), \\\n",
    "                callbacks=[lr_scheduler, model_saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제목: SKT 하나 키움증권, 초대형 인터넷은행 컨소시엄 출범\n",
      "댓글: 좋은 결과로 이어지길 기도합니다 \n",
      "\n",
      "\n",
      "제목: 서울 청량리농수산물시장서 화재 진압 중 \n",
      "댓글: 지금 눈충혈되고 몸에열난다 미세먼지때매\n",
      "\n",
      "\n",
      "제목: 출석안하고도 학위 의왕시장 육성재 윤두준 학위 학점취소\n",
      "댓글: 좋은 결과로 이어지길 기도합니다 \n",
      "\n",
      "\n",
      "제목: 평균 기온 오르는데 한파 횟수는 그대로 이상한 겨울 \n",
      "댓글: 문재앙 탄핵 \n",
      "\n",
      "\n",
      "제목: 여야 4당, 패스트트랙 개혁법안 4개로 압축 국정원법 제외 \n",
      "댓글: 좋은 결실 기대해 봅니다\n",
      "\n",
      "\n",
      "제목: 타스통신 김정은, 열차로 하노이 향해 출발 \n",
      "댓글: 좋은 결과로 이어지길 기도합니다 \n",
      "\n",
      "\n",
      "제목: 최종구 난해한 약관, 비싼 보험 팔려는거 아니냐 직격\n",
      "댓글: 좋은 결과로 이어지길 기도합니다 \n",
      "\n",
      "\n",
      "제목: 넥슨 매각 현실화되면? 게임업계 파장 상당 \n",
      "댓글: 지금 문재인지지하면 사람아니잖아\n",
      "\n",
      "\n",
      "제목: 외교부 방위비협정 가서명 오늘 아냐 주말께 타결 관측\n",
      "댓글: 좋은 결과로 이어지길 기도합니다 \n",
      "\n",
      "\n",
      "제목: 출국금지도 안 돼 자취 감춘 김학의, 조사 가능할까? \n",
      "댓글: 좋은 결과로 이어지길 기도합니다 \n",
      "\n",
      "\n",
      "제목: 포항 앞바다서 규모 4. 1 지진 1년만에 4. 0 이상 발생 \n",
      "댓글: 문재인 간신 또나왔네 \n",
      "\n",
      "\n",
      "제목: 서울교육청 님 쌤 호칭, 강제 아닌 학교 자율로 하세요 \n",
      "댓글: 좋은 결실 기대해 봅니다\n",
      "\n",
      "\n",
      "제목: 우리 땅서 태어난 아이 죽어가는데 국적 따지나\n",
      "댓글: 지금 문재인지지하면 사람아니잖아\n",
      "\n",
      "\n",
      "제목: 그랜저, 메가트럭, 마이티 등 현대 경유차 8만대 리콜\n",
      "댓글: 좋은 결과로 이어지길 기도합니다 \n",
      "\n",
      "\n",
      "제목: 하원, 예정된 브렉시트 이틀 앞두고 공식 연기 법안 통과\n",
      "댓글: 문재앙 탄핵 \n",
      "\n",
      "\n",
      "제목: 그 클럽의 아주 특별한 샴페인 한 잔에 비틀 \n",
      "댓글: 좋은 결과로 이어지길 기도합니다 \n",
      "\n",
      "\n",
      "제목: 몸 키우려 하루에 주사 18방 의사도 이러다 죽는다고 \n",
      "댓글: 좋은 결과로 이어지길 기도합니다 \n",
      "\n",
      "\n",
      "제목: 싼 물건 있다 해서 가보니 세입자 노린 허위 매물 \n",
      "댓글: 좋은 결실 기대해 봅니다\n",
      "\n",
      "\n",
      "제목: 새벽, 여성의 배변 원정 21세기 인도 황당 스토리\n",
      "댓글: 좋은 결과로 이어지길 기도합니다 \n",
      "\n",
      "\n",
      "제목: 대형 화물선 광안대교와 충돌 구조물 일부 파손돼 도로 통제 \n",
      "댓글: 문재인 간신 또나왔네 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ljqpy\n",
    "valids = ljqpy.LoadCSV('ti2re_valid.txt')\n",
    "en = [x[0].split() for x in valids[:100]]\n",
    "rets = s2s.decode_sequence_readout(en, delimiter=' ')\n",
    "\n",
    "for i in range(20):\n",
    "    print('제목: {}'.format(valids[i][0]))\n",
    "    print('댓글: {}'.format(rets[i]))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
