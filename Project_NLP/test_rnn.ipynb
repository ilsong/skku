{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model_body = Word2Vec.load('word2vec_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.4592804   0.2094444  -0.05542162 -0.020831    0.26242614  0.01524775\n",
      " -0.7226699  -0.47200722 -0.0705606  -0.28813025  0.26643282 -0.03091559\n",
      "  0.08962749 -0.21115255  0.16662134 -0.5519736  -0.20509414 -0.32254475\n",
      "  0.64808726  0.05866559  0.5948888  -0.19594432 -0.2377142   0.08834521\n",
      "  0.07252784 -0.04586444  0.3267818  -0.27102795 -0.07346851 -0.26353055\n",
      " -0.05979047  0.18799396 -0.25140342 -0.27716383  0.00930138  0.04287866\n",
      " -0.32841903  0.33082685 -0.51884    -0.060569   -0.25204003 -0.45604196\n",
      "  0.4036232   0.2505236   0.14276965 -0.06402373 -0.3256995  -0.33293334\n",
      " -0.19913198  0.30167952  0.52976894  0.08050191 -0.15973462 -0.12455326\n",
      " -0.11670899 -0.24197766 -0.21457656  0.18805306 -0.06363223 -0.47736612\n",
      " -0.075086   -0.20496695 -0.2016432   0.24578448 -0.39946318 -0.16276109\n",
      "  0.22354816  0.10503105  0.5524417  -0.08516693 -0.2043187   0.14267847\n",
      "  0.45489725  0.34401459 -0.06306169 -0.23092678 -0.3558613   0.14150319\n",
      "  0.24489789 -0.09227451 -0.33964393  0.4612065  -0.02361965 -0.51728046\n",
      " -0.5648891   0.00849935 -0.29871988  0.1662897  -0.48205453  0.03313709\n",
      " -0.29996473 -0.2909094   0.71215206 -0.09164345 -0.01121298  0.4092846\n",
      " -0.17760292  0.29708263 -0.42580956  0.35856467]\n"
     ]
    }
   ],
   "source": [
    "print(model_body.wv[\"학교\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "tag = Komoran()\n",
    "f = open('../Data/Preprocessed/body.txt', encoding=\"utf8\")\n",
    "sentences = f.read().strip().split('\\n')\n",
    "f.close()\n",
    "\n",
    "error = []\n",
    "result = []\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    try:\n",
    "        result.append(tag.morphs(sentence))\n",
    "    except:\n",
    "        result.append(None)\n",
    "        error.append(i)\n",
    "        print(\"Error! \", i)\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../Data/Preprocessed/Morphs/body.txt', \"w\", encoding=\"utf-8\")\n",
    "f.write(str(result))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../Data/Preprocessed/reply.txt', encoding=\"utf-8\")\n",
    "sentences = [sentence[0]['text'] for sentence in list(map(eval, f.read().strip().split(\"\\n\")))]\n",
    "f.close()\n",
    "\n",
    "error_reply = []\n",
    "result_reply = []\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    try:\n",
    "        result_reply.append(tag.morphs(sentence))\n",
    "    except:\n",
    "        result_reply.append(None)\n",
    "        error_reply.append(i)\n",
    "        print(\"Error! \", i)\n",
    "print(len(result_reply))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_total = error+error_reply\n",
    "error_total.sort(reverse=True)\n",
    "\n",
    "for error_idx in error_total:\n",
    "    del result[error_idx]\n",
    "    del result_reply[error_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../Data/Preprocessed/Morphs/body-noerror.txt', \"w\", encoding=\"utf-8\")\n",
    "f.write(str(result))\n",
    "f.close()\n",
    "f = open('../Data/Preprocessed/Morphs/reply-noerror.txt', \"w\", encoding=\"utf-8\")\n",
    "f.write(str(result_reply))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Error가 제거된 데이터 Read\n",
    "\n",
    "f = open('../Data/Preprocessed/Morphs/body-noerror.txt', 'r', encoding='utf-8')\n",
    "result = eval(f.read())\n",
    "f.close()\n",
    "\n",
    "f = open('../Data/Preprocessed/Morphs/reply-noerror.txt', 'r', encoding='utf-8')\n",
    "result_reply = eval(f.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4357\n",
      "4357\n"
     ]
    }
   ],
   "source": [
    "print(len(result))\n",
    "print(len(result_reply))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "### Make vector list to all text of each words\n",
    "\n",
    "x_data, y_data = [], []\n",
    "result_len = len(result)\n",
    "\n",
    "for sentence_idx in range(result_len):\n",
    "    vector_x, vector_y = [], []\n",
    "    \n",
    "    for word in result[sentence_idx]:\n",
    "        try:\n",
    "            vector_x.append(model_total.wv[word])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    for word in result_reply[sentence_idx]:\n",
    "        try:\n",
    "            vector_y.append(model_total.wv[word])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    x_data.append(vector_x)\n",
    "    y_data.append(vector_y)\n",
    "    \n",
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x data shape:  (4357,)\n",
      "y data shape:  (4357,)\n"
     ]
    }
   ],
   "source": [
    "### shape (# of data, # of word, length of embedding vector)\n",
    "\n",
    "print(\"x data shape: \", x_data.shape)\n",
    "print(\"y data shape: \", y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess= tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#for y in y_data[0]:\n",
    "#    print(model_total.wv.most_similar(positive=[y], topn=1))\n",
    "x_data_maxlen = 500\n",
    "y_data_maxlen = 50\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras import backend as K\n",
    "x_data = sequence.pad_sequences(x_data, padding='post', maxlen=x_data_maxlen, dtype=K.floatx())\n",
    "y_data = sequence.pad_sequences(y_data, padding='pre', maxlen=y_data_maxlen, dtype=K.floatx())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4357, 500, 100)\n",
      "(4357, 50, 100)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "print(x_data[0][325])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Dropout, Input\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "target_shape = y_train.shape[1:]\n",
    "latent_dim = 128\n",
    "\n",
    "encoder_inputs = Input(shape=input_shape)\n",
    "#encoder_inputs = BatchNormalization()(encoder_inputs)\n",
    "encoder = LSTM(latent_dim, return_sequences=True, return_state=True, kernel_initializer='zeros', recurrent_initializer='zeros')\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=target_shape)\n",
    "#decoder_inputs = BatchNormalization()(decoder_inputs)\n",
    "decoder = LSTM(latent_dim, return_sequences=True, return_state=True, kernel_initializer='zeros', recurrent_initializer='zeros')\n",
    "decoder_outputs, _, _ = decoder(decoder_inputs, initial_state = encoder_states)\n",
    "decoder_dense = Dense(target_shape[1], activation='tanh')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_outputs)\n",
    "rmsprop = RMSprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='hinge', optimizer=rmsprop, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ 바꿔가면서 해보세요 ######################################\n",
    "num_epochs = 20\n",
    "mini_batch_size = 64\n",
    "######################################################################################\n",
    "history = model.fit([x_data, y_data], y_data, epochs=num_epochs, batch_size=mini_batch_size, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 50\n",
    "b = model.predict([x_data[idx:idx+1], np.zeros_like(y_data[0:1])])\n",
    "for i in range(10):\n",
    "    print(model_total.wv.most_similar(positive=[y_data[idx][i]], topn=1))\n",
    "print()\n",
    "for i in range(10):\n",
    "    print(model_total.wv.most_similar(positive=[b[0][i]], topn=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
