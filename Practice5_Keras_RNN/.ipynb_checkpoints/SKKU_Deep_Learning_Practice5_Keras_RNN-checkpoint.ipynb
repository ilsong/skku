{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice5. Keras-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1432554402066186135\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7209677620\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12690254899001952583\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess= tf.Session(config=config)\n",
    "\n",
    "import sys\n",
    "from tensorflow.python.client import device_lib\n",
    "print (device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. reuters dataset 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 5000\n",
    "# cut texts after this number of words (among top max_features most common words), 바꾸지 마세요!\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(path=\"reuters.npz\",\n",
    "                                                         num_words=max_features,\n",
    "                                                         skip_top=0,\n",
    "                                                         maxlen=None,\n",
    "                                                         test_split=0.2,\n",
    "                                                         seed=113,\n",
    "                                                         start_char=1,\n",
    "                                                         oov_char=2,\n",
    "                                                         index_from=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data shape 확인\n",
    "- x_train, x_test의 형태를 꼭 확인할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape :  (8982,) \ty_train.shape :  (8982,)\n",
      "x_test.shape :  (2246,) \ty_test.shape :  (2246,)\n",
      "\n",
      "len(x_train[0]) :  87 \tlen(x_test[0]) :  145\n",
      "len(x_train[-1]) :  105 \tlen(x_test[-1]) :  272\n"
     ]
    }
   ],
   "source": [
    "print ('x_train.shape : ', x_train.shape,'\\ty_train.shape : ',  y_train.shape)\n",
    "print ('x_test.shape : ', x_test.shape,'\\ty_test.shape : ',  y_test.shape)\n",
    "print ()\n",
    "print ('len(x_train[0]) : ', len(x_train[0]),'\\tlen(x_test[0]) : ', len(x_test[0]))\n",
    "print ('len(x_train[-1]) : ', len(x_train[-1]),'\\tlen(x_test[-1]) : ', len(x_test[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. a list of sequences를 2D Numpy array로 변환\n",
    "- 참고 : https://keras.io/preprocessing/sequence/#pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentence length for embedding is 200\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "################################### 바꿔가면서 해보세요 ################################\n",
    "\n",
    "max_sentence_length = 200\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_sentence_length)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_sentence_length)\n",
    "\n",
    "print ('max sentence length for embedding is %d' % (max_sentence_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification을 위한 cetegorical label 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_label :  46\n",
      "x_train.shape \t: (8982, 200)\n",
      "y_train_onehot.shape : (8982, 46)\n",
      "x_test.shape \t: (2246, 200)\n",
      "y_test_onehot.shape : (2246, 46)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "output_shape = np.max(y_train) + 1\n",
    "\n",
    "print (\"max_label : \", output_shape)\n",
    "\n",
    "y_train_onehot=np_utils.to_categorical(y_train,output_shape)\n",
    "y_test_onehot=np_utils.to_categorical(y_test,output_shape)\n",
    "\n",
    "print ('x_train.shape \\t: ' + str(x_train.shape))\n",
    "print ('y_train_onehot.shape : ' + str(y_train_onehot.shape))\n",
    "print ('x_test.shape \\t: ' + str(x_test.shape))\n",
    "print ('y_test_onehot.shape : ' + str(y_test_onehot.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Embedding vector length 설정\n",
    "- Embedding layer : https://keras.io/layers/embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding vector size is 32\n"
     ]
    }
   ],
   "source": [
    "################################### 바꿔가면서 해보세요 ################################\n",
    "\n",
    "embedding_vecor_length = 32    \n",
    "\n",
    "###################################################################################\n",
    "print ('embedding vector size is %d'% (embedding_vecor_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model 만들기\n",
    "- Keras Documentation : https://keras.io\n",
    "- Embedding layer : https://keras.io/layers/embeddings/\n",
    "- Recurrent layer : https://keras.io/layers/recurrent/\n",
    "- Convolution layer : https://keras.io/layers/convolutional/\n",
    "- Drop out : https://keras.io/layers/core/#dropout\n",
    "- Sequence classification with LSTM : https://keras.io/getting-started/sequential-model-guide/#sequence-classification-with-lstm\n",
    "- Documentation 참고하면서 다양한 형태로 모델을 만들어보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Dropout, Input\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_layer = Input(shape=input_shape)\n",
    "layer = input_layer\n",
    "\n",
    "################################### Documentation 참고해서 레이어를 바꿔보세요 ################################\n",
    "\n",
    "layer = Embedding(max_features, 32, embeddings_initializer='uniform')(layer)\n",
    "#layer = LSTM(units=64, return_sequences=False)(layer)\n",
    "#layer = Dropout(0.25)(layer)\n",
    "layer = GRU(64)(layer)\n",
    "layer = Dropout(0.2)(layer)\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "layer = Dense(output_shape, activation='softmax')(layer)\n",
    "\n",
    "output_layer = layer\n",
    "model = Model(inputs=[input_layer], outputs=[output_layer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer 설정, 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, RMSprop\n",
    "################################ 바꿔가면서 해보세요 ######################################\n",
    "rmsprop = RMSprop()\n",
    "######################################################################################\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary() 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 32)           160000    \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 64)                18624     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 181,614\n",
      "Trainable params: 181,614\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 visualization (선택)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f515c0e9748>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "plot_model(model,'model_image.png', show_layer_names=False, show_shapes=True)\n",
    "model_img=mpimg.imread('model_image.png')\n",
    "plt.figure(figsize=[10,50])\n",
    "plt.imshow(model_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/50\n",
      "8982/8982 [==============================] - 87s 10ms/step - loss: 2.2192 - acc: 0.3773 - val_loss: 1.9389 - val_acc: 0.4849\n",
      "Epoch 2/50\n",
      "8982/8982 [==============================] - 82s 9ms/step - loss: 1.7836 - acc: 0.5169 - val_loss: 1.7247 - val_acc: 0.5641\n",
      "Epoch 3/50\n",
      "8982/8982 [==============================] - 85s 9ms/step - loss: 1.6401 - acc: 0.5686 - val_loss: 1.6648 - val_acc: 0.5775\n",
      "Epoch 4/50\n",
      "8982/8982 [==============================] - 82s 9ms/step - loss: 1.5713 - acc: 0.5927 - val_loss: 1.6307 - val_acc: 0.5806\n",
      "Epoch 5/50\n",
      "8982/8982 [==============================] - 83s 9ms/step - loss: 1.5146 - acc: 0.6119 - val_loss: 1.5913 - val_acc: 0.5957\n",
      "Epoch 6/50\n",
      "8982/8982 [==============================] - 82s 9ms/step - loss: 1.4651 - acc: 0.6187 - val_loss: 1.5717 - val_acc: 0.6091\n",
      "Epoch 7/50\n",
      "8982/8982 [==============================] - 79s 9ms/step - loss: 1.4168 - acc: 0.6387 - val_loss: 1.5187 - val_acc: 0.6149\n",
      "Epoch 8/50\n",
      "8982/8982 [==============================] - 77s 9ms/step - loss: 1.3526 - acc: 0.6578 - val_loss: 1.5105 - val_acc: 0.6211\n",
      "Epoch 9/50\n",
      "8982/8982 [==============================] - 78s 9ms/step - loss: 1.2990 - acc: 0.6717 - val_loss: 1.4584 - val_acc: 0.6407\n",
      "Epoch 10/50\n",
      "8982/8982 [==============================] - 78s 9ms/step - loss: 1.2441 - acc: 0.6855 - val_loss: 1.4638 - val_acc: 0.6394\n",
      "Epoch 11/50\n",
      "8982/8982 [==============================] - 77s 9ms/step - loss: 1.1857 - acc: 0.7010 - val_loss: 1.4080 - val_acc: 0.6523\n",
      "Epoch 12/50\n",
      "8982/8982 [==============================] - 77s 9ms/step - loss: 1.1299 - acc: 0.7192 - val_loss: 1.4425 - val_acc: 0.6229\n",
      "Epoch 13/50\n",
      "8982/8982 [==============================] - 77s 9ms/step - loss: 1.0785 - acc: 0.7334 - val_loss: 1.3626 - val_acc: 0.6638\n",
      "Epoch 14/50\n",
      "8982/8982 [==============================] - 78s 9ms/step - loss: 1.0189 - acc: 0.7450 - val_loss: 1.3346 - val_acc: 0.6719\n",
      "Epoch 15/50\n",
      "8982/8982 [==============================] - 78s 9ms/step - loss: 0.9648 - acc: 0.7570 - val_loss: 1.3165 - val_acc: 0.6745\n",
      "Epoch 16/50\n",
      "8982/8982 [==============================] - 78s 9ms/step - loss: 0.9180 - acc: 0.7720 - val_loss: 1.3460 - val_acc: 0.6696\n",
      "Epoch 17/50\n",
      "8982/8982 [==============================] - 78s 9ms/step - loss: 0.8743 - acc: 0.7790 - val_loss: 1.3041 - val_acc: 0.6812\n",
      "Epoch 18/50\n",
      "8982/8982 [==============================] - 77s 9ms/step - loss: 0.8349 - acc: 0.7920 - val_loss: 1.2482 - val_acc: 0.6968\n",
      "Epoch 19/50\n",
      "8982/8982 [==============================] - 78s 9ms/step - loss: 0.8007 - acc: 0.8022 - val_loss: 1.2369 - val_acc: 0.7021\n",
      "Epoch 20/50\n",
      "8982/8982 [==============================] - 77s 9ms/step - loss: 0.7654 - acc: 0.8142 - val_loss: 1.3672 - val_acc: 0.6883\n",
      "Epoch 21/50\n",
      "8982/8982 [==============================] - 77s 9ms/step - loss: 0.7325 - acc: 0.8166 - val_loss: 1.2498 - val_acc: 0.7044\n",
      "Epoch 22/50\n",
      "8982/8982 [==============================] - 78s 9ms/step - loss: 0.7115 - acc: 0.8281 - val_loss: 1.2296 - val_acc: 0.7119\n",
      "Epoch 23/50\n",
      "8982/8982 [==============================] - 78s 9ms/step - loss: 0.6837 - acc: 0.8358 - val_loss: 1.2306 - val_acc: 0.7110\n",
      "Epoch 24/50\n",
      "8982/8982 [==============================] - 78s 9ms/step - loss: 0.6647 - acc: 0.8429 - val_loss: 1.2202 - val_acc: 0.7075\n",
      "Epoch 25/50\n",
      "8982/8982 [==============================] - 78s 9ms/step - loss: 0.6419 - acc: 0.8457 - val_loss: 1.2519 - val_acc: 0.7061\n",
      "Epoch 26/50\n",
      "8982/8982 [==============================] - 77s 9ms/step - loss: 0.6226 - acc: 0.8532 - val_loss: 1.2598 - val_acc: 0.7195\n",
      "Epoch 27/50\n",
      "8982/8982 [==============================] - 78s 9ms/step - loss: 0.5983 - acc: 0.8570 - val_loss: 1.2385 - val_acc: 0.7119\n",
      "Epoch 28/50\n",
      "8982/8982 [==============================] - 77s 9ms/step - loss: 0.5944 - acc: 0.8622 - val_loss: 1.2373 - val_acc: 0.7159\n",
      "Epoch 29/50\n",
      "8982/8982 [==============================] - 78s 9ms/step - loss: 0.5613 - acc: 0.8684 - val_loss: 1.2549 - val_acc: 0.7075\n",
      "Epoch 30/50\n",
      "8982/8982 [==============================] - 78s 9ms/step - loss: 0.5434 - acc: 0.8754 - val_loss: 1.2381 - val_acc: 0.7142\n",
      "Epoch 31/50\n",
      "8982/8982 [==============================] - 78s 9ms/step - loss: 0.5297 - acc: 0.8769 - val_loss: 1.2605 - val_acc: 0.7150\n",
      "Epoch 32/50\n",
      "8982/8982 [==============================] - 78s 9ms/step - loss: 0.5171 - acc: 0.8785 - val_loss: 1.2426 - val_acc: 0.7173\n",
      "Epoch 33/50\n",
      "8982/8982 [==============================] - 77s 9ms/step - loss: 0.5012 - acc: 0.8857 - val_loss: 1.2615 - val_acc: 0.7124\n",
      "Epoch 34/50\n",
      "8982/8982 [==============================] - 78s 9ms/step - loss: 0.4868 - acc: 0.8879 - val_loss: 1.2604 - val_acc: 0.7150\n",
      "Epoch 35/50\n",
      "8982/8982 [==============================] - 78s 9ms/step - loss: 0.4686 - acc: 0.8919 - val_loss: 1.2940 - val_acc: 0.7097\n",
      "Epoch 36/50\n",
      "8982/8982 [==============================] - 78s 9ms/step - loss: 0.4714 - acc: 0.8883 - val_loss: 1.3065 - val_acc: 0.7084\n",
      "Epoch 37/50\n",
      "8982/8982 [==============================] - 78s 9ms/step - loss: 0.4489 - acc: 0.8946 - val_loss: 1.3002 - val_acc: 0.7084\n",
      "Epoch 38/50\n",
      "8982/8982 [==============================] - 77s 9ms/step - loss: 0.4455 - acc: 0.8967 - val_loss: 1.2584 - val_acc: 0.7191\n",
      "Epoch 39/50\n",
      "8982/8982 [==============================] - 78s 9ms/step - loss: 0.4244 - acc: 0.8996 - val_loss: 1.2972 - val_acc: 0.7093\n",
      "Epoch 40/50\n",
      "8982/8982 [==============================] - 78s 9ms/step - loss: 0.4116 - acc: 0.9059 - val_loss: 1.3064 - val_acc: 0.7075\n",
      "Epoch 41/50\n",
      "8982/8982 [==============================] - 81s 9ms/step - loss: 0.4133 - acc: 0.9058 - val_loss: 1.3128 - val_acc: 0.6910\n",
      "Epoch 42/50\n",
      "5888/8982 [==================>...........] - ETA: 26s - loss: 0.3876 - acc: 0.9110"
     ]
    }
   ],
   "source": [
    "################################ 바꿔가면서 해보세요 ######################################\n",
    "num_epochs = 50\n",
    "mini_batch_size = 32\n",
    "######################################################################################\n",
    "history = model.fit(x_train, y_train_onehot,validation_data=[x_test, y_test_onehot], epochs=num_epochs, batch_size=mini_batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mission :  Test Accuray 75% 이상 달성하기\n",
    "- 바꿀 수 있는 것 : max_sentence_length, embedding_vecor_length, num_epochs, mini_batch_size, Optimizer, 모델 구조\n",
    "- 위 요소들을 바꿔보면서 각각의 요소와 최종 결과의 관계를 한번 파악해보세요. (Overfitting vs Underfitting)\n",
    "- 달성한 Accuracy가 보이게 6. Visualization 까지 실행된 코드를 제출해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot training graph\n",
    "plt.clf()\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.grid(True)\n",
    "plt.yticks(np.arange(0, max(max(history.history['loss']),max(history.history['val_loss'])), 0.1))\n",
    "plt.xticks(np.arange(0, num_epochs, 2))\n",
    "plt.ylim([0.0, max(max(history.history['loss']), max(history.history['val_loss']))])\n",
    "plt.xlim([0, num_epochs])\n",
    "\n",
    "plt.plot(history.history['loss'][:], lw=2, label='Training Loss')\n",
    "plt.plot(history.history['acc'][:], lw=2, label='Training Acc')\n",
    "plt.plot(history.history['val_loss'][:], lw=2, label='Test Loss')\n",
    "plt.plot(history.history['val_acc'][:], lw=2, label='Test Acc')\n",
    "\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training Loss','Training Acc', 'Test Loss','Test Acc'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "print ('Best accuray : ', round(np.max(np.array(history.history['val_acc'])),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
